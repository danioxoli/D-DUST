{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a595331",
   "metadata": {},
   "source": [
    "# D-DUST Data Grid Processing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9ee1d",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b5dae",
   "metadata": {},
   "source": [
    "Check the following link for Data Management Plan and the Variable list table: <br>\n",
    "**1. [Data Management Plan (DMP)](https://docs.google.com/document/d/1n3PVat7PBTG76JnINOkL2pvBZuKQlakZkTgqNj39oAQ/edit#)**<br>\n",
    "**2. [Data Table](https://docs.google.com/spreadsheets/d/1-5pwMSc1QlFyC8iIaA-l1fWhWtpqVio2/edit#gid=91313358)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da51273",
   "metadata": {},
   "source": [
    "First, the other notebooks must be used in order to retrieve ready to be processed data in the same time range. For each dataset a description is provided in these notebooks:\n",
    "- [Satellite Variables Request Notebook](https://github.com/opengeolab/D-DUST/blob/WP2/Satellite%20Variables%20Request.ipynb): satellite data preparation\n",
    "- [Model Variables Request Notebook](https://github.com/opengeolab/D-DUST/blob/WP2/Model%20Variables%20Request.ipynb): CAMS and ERA5 data preparation\n",
    "- [Ground Sensor Variables Request Notebook](https://github.com/opengeolab/D-DUST/blob/WP2/Ground%20Sensor%20Variables%20Request%20-%20ARPA%20Lombardia.ipynb): ARPA ground  sensors and ESA Air Quality stations preparation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6f2f5",
   "metadata": {},
   "source": [
    "This notebook summirized the physical variables selected for the project and how they are processed for the successive phase of feature selection. <br>\n",
    "These variables are divided into <u>4 categories</u>, as shown in the **Data Table**:\n",
    "1. **Map Layer**: time-invariant layer used to describe Lombardy region morphology and its features (e.g. elevation, infrastructures, land use and cover etc.)\n",
    "2. **Model**: data retrieved from a model that uses satellite and in-situ observations of meteorological and air quality data as input (e.g. ERA5, CAMS)\n",
    "3. **Satellite**: data obtained directly from satellite observations (e.g. Sentinel-5P Tropomi or Terra&Aqua MODIS)\n",
    "4. **Ground Sensor**: data retrieved from ground monitoring stations measuring air quality and meteorological variables (in this case ARPA Lombardia and ESA LPS Air Quality Stations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a3521-3398-4657-84a2-2cf5467edf2c",
   "metadata": {},
   "source": [
    "All the physical variables are represented using zonal statistics (depending on the variable the summary statistic can be sum, mean, count...). \n",
    "For detailed information of the datasets used check the DMP, Data Table and the data preparation notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0316e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff716c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import scipy.interpolate\n",
    "from scipy.interpolate import griddata\n",
    "import rasterstats as rstat\n",
    "import rioxarray\n",
    "import shapely.speedups\n",
    "shapely.speedups.enable()\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import  MultiLineString\n",
    "from rasterio.enums import Resampling\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import methods defined for the project\n",
    "from functions import my_methods\n",
    "\n",
    "# Get current working directory path\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972837ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import grids and time range definition\n",
    "\n",
    "Three grids with different spatial resolution are used in this project:\n",
    "1. **0_1** grid: 0.1° x 0.1° resolution - Grid with CAMS Model spatial resolution.\n",
    "2. **0_066** grid: 0.066° x 0.066° resolution - Grid with the Sentinel-5P approximate spatial resolution.\n",
    "3. **0_01** grid: 0.01° x 0.01° resolution- Grid generated with at most one ARPA monitoring station for each pixel.\n",
    "\n",
    "These grids are defined as bounding box of the Lombardy region layer applying a buffer of 20 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf62a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this widget is possible to select from the dropdown list\n",
    "name = widgets.Dropdown(\n",
    "    options=['0_1', '0_066', '0_01'],\n",
    "    description='name:',\n",
    "    disabled=False)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion for lengths and areas\n",
    "m_to_km = 10**(-3)\n",
    "m2_to_km2 = 10**(-6)\n",
    "\n",
    "# To increase CAMS data resolution depending on the grid cell size (necessary zonal statistics calculation)\n",
    "if name.value == '0_1':\n",
    "    upscale_factor = 1\n",
    "    cell_area = 86587928.50 # meters. Mean cell size of the grid\n",
    "if name.value == '0_066':\n",
    "    upscale_factor = 5\n",
    "    cell_area = 37725255.64 # meters. Mean cell size of the grid\n",
    "if name.value == '0_01':\n",
    "    upscale_factor = 15  \n",
    "    cell_area = 866036.85 # meters. Mean cell size of the grid\n",
    "\n",
    "grid_path = my_methods.select_grid(name.value)\n",
    "#Select empty grid\n",
    "grid = gpd.read_file(cwd + grid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ed688",
   "metadata": {},
   "source": [
    "Selection of **manuring periods** defined in the **date.json** file, providing the year and the time range (using a custom week with mm-dd format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = open('date.json') # Select time range\n",
    "date = json.load(d)\n",
    "year = date['year']\n",
    "custom_week = date['custom_week']\n",
    "# Plot calendar of weeks defined in the .date.json file\n",
    "calendar = my_methods.manuring_periods(year, custom_week)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bcb9bf-7afd-47c4-bc09-a4bb5a4ecd7d",
   "metadata": {},
   "source": [
    "Set the start and end dates, using the weeks defined in the json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41eddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select start and end date of the corresponding selected week:\n",
    "start_date = datetime.datetime.strptime((str(year)+'-'+custom_week[0]), \"%Y-%m-%d\").date()\n",
    "end_date = datetime.datetime.strptime((str(year)+'-'+custom_week[1]), \"%Y-%m-%d\").date()\n",
    "print(\"The starting date is\", start_date,\"and the ending date is\" , end_date,\". The date is defined as yyyy-mm-dd.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02584c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479eb93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Map Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12705ddb-3a0d-43b3-978e-33ffbbfc874e",
   "metadata": {},
   "source": [
    "<a id='map-layers'></a>[**SKIP MAP LAYERS**](#not-map-layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fae5f",
   "metadata": {},
   "source": [
    "Map Layers don't update as frequently as satellite, model and ground sensor data.\n",
    "They can be stored in folders and replaced when a newer version is provided. It is possible to save a preprocessed version of the grids at the end of the Map Layer section, in order to avoid calculations when these data remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa1b51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [Gridded Population of the World - GPW](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11)<br>\n",
    "To provide estimates of population density for the year 2020, based on counts consistent with national censuses and population registers, as raster data to facilitate data integration.\n",
    "Input reference system EPSG: 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81549559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_path = cwd + '/population/population.tif'\n",
    "pop = rio.open(pop_path)\n",
    "\n",
    "pop_array = pop.read(1)\n",
    "pop_array[pop_array<0]=np.nan\n",
    "pop_affine = pop.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pop_array, affine=pop_affine, nodata=np.nan, stats=['sum'])), how='left')\n",
    "grid = grid.rename(columns={\"sum\": \"pop\"})\n",
    "grid['pop'] = grid['pop'] / cell_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbe55e-ab16-47fc-a8e7-63e0371c7f8a",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2bfc48",
   "metadata": {},
   "source": [
    "### [Digital Terrain Model - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7BFC06681A-2403-481F-B6FE-5F952DD48BAF%7D)<br>\n",
    "Digital Terrain Model of Lombardy region with 20 m resolution. Reference system EPSG:4326.\n",
    "1. Elevation = Lombardy Region DTM with 20 m resolution\n",
    "2. Aspect = calculated from the elevation layer\n",
    "3. Slope = calculated from the elevation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = cwd + '/terrain/dtm20.tif'\n",
    "aspect_path = cwd + '/terrain/aspect.tif'\n",
    "slope_path = cwd + '/terrain/slope.tif'\n",
    "dtm = rio.open(dtm_path)\n",
    "aspect = rio.open(aspect_path)\n",
    "slope = rio.open(slope_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for the elevation\n",
    "dtm_array = dtm.read(1)\n",
    "dtm_array[dtm_array<0]=np.nan\n",
    "dtm_affine = dtm.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, dtm_array, affine=dtm_affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"h_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7924f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for aspect\n",
    "aspect_array = aspect.read(1)\n",
    "aspect_array[aspect_array<0]=np.nan\n",
    "aspect_affine = aspect.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aspect_array, affine=aspect_affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aspect_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d494fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for slope\n",
    "slope_array = slope.read(1)\n",
    "slope_array[slope_array<0]=np.nan\n",
    "slope_affine = slope.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, slope_array, affine=slope_affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"slope_mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74615632",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e7153-a9e8-4b3d-b2a4-37dac457d0e7",
   "metadata": {},
   "source": [
    "### [Air quality zones - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B20A92F5C-A3EC-402C-B908-EE32EB8644C2%7D)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838ce3c-6cbd-4d8d-9a3a-e6ad4cd71dcc",
   "metadata": {},
   "source": [
    "Air quality zoning. There are 5 categories:\n",
    "- A = 1. Highly urbanized plains\n",
    "- B = 2. Plains\n",
    "- C = 3. Prealpi, Appennino and mountains\n",
    "- D = 4. Valley floor\n",
    "- Agg = 5. Urban agglomarated area (Milano, Bergamo, Brescia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422872c9-6266-4d09-bef7-4f597210abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_zones_path = cwd + '/zones/air_quality_zones.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af306f7-6a0e-43b6-97b4-1713fb61caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_zones = rio.open(aq_zones_path)\n",
    "aq_zones_array = aq_zones.read(1).astype('float64') \n",
    "aq_zones_array[aq_zones_array<1.0]=np.nan\n",
    "aq_zones_affine = aq_zones.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edd86b-3bd2-4e41-b2a2-65350bb870aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_aq_zones = rstat.zonal_stats(grid, aq_zones_array, affine=aq_zones_affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_aq_zones]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"aq_zone\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225197d-464e-4962-a203-2fff45ebf96f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff847955-14ec-4fb1-b0ed-b444231fa512",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [Zone pedoclimatiche - Allegato B Bollettino Nitrati](https://www.ersaf.lombardia.it/it/servizi-al-territorio/nitrati/bollettini-nitrati/bollettino-nitrati)<br>\n",
    "- Alpi = 1\n",
    "- Prealpi Occidentali = 2\n",
    "- Prealpi Orientali = 3\n",
    "- Pianura Occidentale = 4\n",
    "- Pianura Centrale = 5\n",
    "- Pianura Orientale = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53819ce1-c27c-4ded-b886-1a0d647560c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_zones_path = cwd + '/zones/climate_zones.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772280d3-6892-4aac-b151-bc6d32f45599",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_zones = rio.open(clim_zones_path)\n",
    "clim_zones_array = clim_zones.read(1).astype('float64') \n",
    "clim_zones_array[clim_zones_array<1.0]=np.nan\n",
    "clim_zones_affine = clim_zones.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd536832-618e-492d-8ad0-1d37e36dcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_clim_zones = rstat.zonal_stats(grid, clim_zones_array, affine=clim_zones_affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_clim_zones]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"clim_zone\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe2abe",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc4356",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [DUSAF - Land use - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B18EE7CDC-E51B-4DFB-99F8-3CF416FC3C70%7D) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa462e06-3be7-4efa-88e6-7a5df816e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.to_crs(32632)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe9826",
   "metadata": {},
   "source": [
    "Consists in a multi-temporal geographic database that classifies land based on major land cover and land use types. It's required to provide this file in .tiff format (rasterized). \n",
    "Reference system EPSG:4326.<br>\n",
    "\n",
    "Interesting DUSAF Land Use categories for Lombardy region:\n",
    "- 2 = Agricultural areas\n",
    "- 3 = Wooded territories and semi-natural environments\n",
    "- 4 = Wetlands\n",
    "- 5 = Water bodies\n",
    "- 11 = Urbanised areas\n",
    "- 12 = Production facilities, large plants and communication networks\n",
    "- 13 = Mining areas, landfills, construction sites, waste and abandoned land\n",
    "- 14 = Non-agricultural green areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dusaf_path = cwd + '/land_use_cover/dusaf.tif' # Set DUSAF raster path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a13eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dusaf = rio.open(dusaf_path) #open DUSAF with rasterio\n",
    "dusaf_array = dusaf.read(1).astype('float64') \n",
    "dusaf_array[dusaf_array<1.0]=np.nan\n",
    "dusaf_affine = dusaf.transform\n",
    "dusaf_cell = abs(dusaf_affine[0]*dusaf_affine[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_dusaf = rstat.zonal_stats(grid, dusaf_array, affine=dusaf_affine, nodata=0.0, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_dusaf]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"dusaf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_dusaf = rstat.zonal_stats(grid, dusaf_array, affine=dusaf_affine, nodata=0.0, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_dusaf, orient='columns')\n",
    "p = p*dusaf_cell/cell_area\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['dsf2','dsf3','dsf4','dsf5','dsf11','dsf12','dsf13','dsf14']] = 0.0\n",
    "\n",
    "grid['p2'] = p[2.0]\n",
    "grid['p3'] = p[3.0]\n",
    "grid['p4'] = p[4.0]\n",
    "grid['p5'] = p[5.0]\n",
    "grid['p11'] = p[11.0]\n",
    "grid['p12'] = p[12.0]\n",
    "grid['p13'] = p[13.0]\n",
    "grid['p14'] = p[14.0]\n",
    "grid.dsf2 = np.nanmax(grid[['dsf2', 'p2']],1)\n",
    "grid.dsf3 = np.nanmax(grid[['dsf3', 'p3']],1)\n",
    "grid.dsf4 = np.nanmax(grid[['dsf4', 'p4']],1)\n",
    "grid.dsf5 = np.nanmax(grid[['dsf5', 'p5']],1)\n",
    "grid.dsf11 = np.nanmax(grid[['dsf11', 'p11']],1)\n",
    "grid.dsf12 = np.nanmax(grid[['dsf12', 'p12']],1)\n",
    "grid.dsf13 = np.nanmax(grid[['dsf13', 'p13']],1)\n",
    "grid.dsf14 = np.nanmax(grid[['dsf14', 'p14']],1)\n",
    "\n",
    "grid = grid.drop(columns=['p2', 'p3', 'p4', 'p5', 'p11', 'p12', 'p13', 'p14'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba17ce",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b2e46",
   "metadata": {},
   "source": [
    "### [SIARL - Agricultural use - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B83483117-8742-4A1F-A16E-3A48AEE2EBE2%7D) <br>\n",
    "This layer contains the agricoltural use for each cadastral parcel provided by SIARL Catalog for the Lombardy region. This file is converted to .tif format. Reference system EPSG:4326. <br>\n",
    "\n",
    "Interesting SIARL Agricoltural use categories:\n",
    "- 2 = Cereal\n",
    "- 9 = Mais\n",
    "- 12 = Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "siarl_path = cwd + '/land_use_cover/siarl.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "siarl = rio.open(siarl_path) #open SIARL with rasterio\n",
    "siarl_array = siarl.read(1).astype('float64') \n",
    "siarl_array[siarl_array<1.0]=np.nan\n",
    "siarl_affine = siarl.transform\n",
    "siarl_cell = abs(siarl_affine[0]*siarl_affine[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198dee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_siarl = rstat.zonal_stats(grid, siarl_array, affine=siarl_affine, nodata=128.0, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_siarl]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"siarl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_siarl = rstat.zonal_stats(grid, siarl_array, affine=siarl_affine, nodata=128.0, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_siarl, orient='columns')\n",
    "p = p*siarl_cell/cell_area\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['siarl2','siarl9','siarl12']] = 0.0\n",
    "\n",
    "grid['p2'] = p[2.0]\n",
    "grid['p9'] = p[9.0]\n",
    "grid['p12'] = p[12.0]\n",
    "grid.siarl2 = np.nanmax(grid[['siarl2', 'p2']],1)\n",
    "grid.siarl9 = np.nanmax(grid[['siarl9', 'p9']],1)\n",
    "grid.siarl12 = np.nanmax(grid[['siarl12', 'p12']],1)\n",
    "grid = grid.drop(columns=['p2', 'p9', 'p12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b900cf-c8de-4e39-9d29-b3f1ae1bb2b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9011a5",
   "metadata": {},
   "source": [
    "### Soil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f95e87",
   "metadata": {},
   "source": [
    "In this part information concerning soil and vegetation is considered, such as:\n",
    "- Soil type: classification fron [OpenLandMap USDA Soil Texture classification](https://developers.google.com/earth-engine/datasets/catalog/OpenLandMap_SOL_SOL_TEXTURE-CLASS_USDA-TT_M_v02)\n",
    "- Soil text: classification obtained from [Carta Pedologica 250k](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7BA7138B8A-9025-4802-82BC-52267B60A3D7%7D) on Geoportale Regione Lombardia\n",
    "\n",
    "Soil type from **Open Land Map - USDA Soil Classification** (missing value 3, 10, 11, 12 in this dataset for Lombardy region). EPSG 4326: \n",
    "- 1 = Clay\n",
    "- 2 = Silty Clay\n",
    "- 3 = Sandy Clay\n",
    "- 4 = Clay Loeam\n",
    "- 5 = Silty Clay Loam\n",
    "- 6 = Sandy Clay Loam\n",
    "- 7 = Loam\n",
    "- 8 = Silt Loam\n",
    "- 9 = Sandy Loam\n",
    "- 10 = Silt\n",
    "- 11 = Loamy Sand\n",
    "- 12 = Sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_type_path = cwd + '/terrain/soil_type.tif'\n",
    "soil_text_path = cwd + '/terrain/carta_pedologica.tif'  #Carta pedologica\n",
    "\n",
    "soil_type = rio.open(soil_type_path)\n",
    "soil_text = rio.open(soil_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ac883",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_type_array = soil_type.read(1).astype('float64') \n",
    "soil_type_array[soil_type_array<1.0]=np.nan\n",
    "soil_affine = soil_type.transform\n",
    "soil_cell = abs(soil_affine[0]*soil_affine[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26875fd1-73d2-4c3d-a6d1-788eb41e134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_text.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cead2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_soil_type = rstat.zonal_stats(grid, soil_type_array, affine=soil_affine, nodata=255, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_soil_type]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"soil\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d72647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_soil = rstat.zonal_stats(grid, soil_type_array, affine=soil_affine, nodata=255, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_soil, orient='columns')\n",
    "p = p*soil_cell/cell_area\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['soil1','soil2','soil4','soil5','soil7','soil8','soil9']] = 0.0\n",
    "\n",
    "grid['p1'] = p[1.0]\n",
    "grid['p2'] = p[2.0]\n",
    "#grid['p3'] = p[3.0]\n",
    "grid['p4'] = p[4.0]\n",
    "grid['p5'] = p[5.0]\n",
    "#grid['p6'] = p[6.0]\n",
    "grid['p7'] = p[7.0]\n",
    "grid['p8'] = p[8.0]\n",
    "grid['p9'] = p[9.0]\n",
    "#grid['p10'] = p[10.0]\n",
    "#grid['p11'] = p[11.0]\n",
    "#grid['p12'] = p[12.0]\n",
    "\n",
    "grid.soil1 = np.nanmax(grid[['soil1', 'p1']],1)\n",
    "grid.soil2 = np.nanmax(grid[['soil2', 'p2']],1)\n",
    "#grid.soil3 = np.nanmax(grid[['soil3', 'p3']],1)\n",
    "grid.soil4 = np.nanmax(grid[['soil4', 'p4']],1)\n",
    "grid.soil5 = np.nanmax(grid[['soil5', 'p5']],1)\n",
    "#grid.soil6 = np.nanmax(grid[['soil6', 'p6']],1)\n",
    "grid.soil7 = np.nanmax(grid[['soil7', 'p7']],1)\n",
    "grid.soil8 = np.nanmax(grid[['soil8', 'p8']],1)\n",
    "grid.soil9 = np.nanmax(grid[['soil9', 'p9']],1)\n",
    "#grid.soil10 = np.nanmax(grid[['soil10', 'p10']],1)\n",
    "#grid.soil11 = np.nanmax(grid[['soil11', 'p11']],1)\n",
    "#grid.soil12 = np.nanmax(grid[['soil12', 'p12']],1)\n",
    "\n",
    "grid = grid.drop(columns=['p1', 'p2', 'p4', 'p5', 'p7', 'p8', 'p9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436c1da",
   "metadata": {},
   "source": [
    "Soil texture type from **Carta Pedologica Regione Lombardia**:\n",
    "- 1 = Argillosa fine\n",
    "- 2 = Argillosa molto fine\n",
    "- 3 = Franca fine\n",
    "- 4 = Franca grossolana\n",
    "- 5 = Limosa fine\n",
    "- 6 = Limosa grossolana\n",
    "- 7 = Sabbiosa\n",
    "- 8 = Scheletrico-Argillosa\n",
    "- 9 = Scheletrico-Franca\n",
    "- 10 = Scheletrico-Sabbiosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_text_array = soil_text.read(1).astype('float64') \n",
    "soil_text_affine = soil_text.transform\n",
    "soil_text_cell = abs(soil_text_affine[0]*soil_text_affine[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86513bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_soil_text = rstat.zonal_stats(grid, soil_text_array, affine=soil_text_affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_soil_text]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"soil_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_soil_text = rstat.zonal_stats(grid, soil_text_array, affine=soil_text_affine, nodata=np.nan, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_soil_text, orient='columns')\n",
    "p = p*soil_text_cell/cell_area\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['soil_text1','soil_text2','soil_text3','soil_text4',\n",
    "                                  'soil_text5','soil_text6','soil_text7','soil_text8',\n",
    "                                  'soil_text9','soil_text10']] = 0.0\n",
    "\n",
    "grid['p1'] = p[1.0]\n",
    "grid['p2'] = p[2.0]\n",
    "grid['p3'] = p[3.0]\n",
    "grid['p4'] = p[4.0]\n",
    "grid['p5'] = p[5.0]\n",
    "grid['p6'] = p[6.0]\n",
    "grid['p7'] = p[7.0]\n",
    "grid['p8'] = p[8.0]\n",
    "grid['p9'] = p[9.0]\n",
    "grid['p10'] = p[10.0]\n",
    "grid.soil_text1 = np.nanmax(grid[['soil_text1', 'p1']],1)\n",
    "grid.soil_text2 = np.nanmax(grid[['soil_text2', 'p2']],1)\n",
    "grid.soil_text3 = np.nanmax(grid[['soil_text3', 'p3']],1)\n",
    "grid.soil_text4 = np.nanmax(grid[['soil_text4', 'p4']],1)\n",
    "grid.soil_text5 = np.nanmax(grid[['soil_text5', 'p5']],1)\n",
    "grid.soil_text6 = np.nanmax(grid[['soil_text6', 'p6']],1)\n",
    "grid.soil_text7 = np.nanmax(grid[['soil_text7', 'p7']],1)\n",
    "grid.soil_text8 = np.nanmax(grid[['soil_text8', 'p8']],1)\n",
    "grid.soil_text9 = np.nanmax(grid[['soil_text9', 'p9']],1)\n",
    "grid.soil_text10 = np.nanmax(grid[['soil_text10', 'p10']],1)\n",
    "\n",
    "grid = grid.drop(columns=['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9','p10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abbb74",
   "metadata": {},
   "source": [
    "### [Road Infrastructures - Geoportale Lombardia (DBTR 2019)](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B17D4656F-2E9D-4951-9DC1-4AD32C0959B1%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce0a36",
   "metadata": {},
   "source": [
    "**Point layers** considered:\n",
    "1. Intersection between primary roads including highways\n",
    "2. Intersection between primary and secondary roads\n",
    "3. Intersection between secondary roads\n",
    "\n",
    "Input reference system EPSG: 4326. Converted to 32632:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_prim_path = cwd + '/road_infrastructures/inters_highway_prim_road.gpkg'\n",
    "int_prim_sec_path = cwd + '/road_infrastructures/inters_prim_sec_road.gpkg'\n",
    "int_sec_path = cwd + '/road_infrastructures/inters_sec_road.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dfe4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_prim = gpd.read_file(int_prim_path).to_crs(32632)\n",
    "int_prim_sec = gpd.read_file(int_prim_sec_path).to_crs(32632)\n",
    "int_sec = gpd.read_file(int_sec_path).to_crs(32632)\n",
    "\n",
    "df_dict = {'int_prim':int_prim,\n",
    "          'int_prim_sec':int_prim_sec, 'int_sec': int_sec}\n",
    "\n",
    "for key in df_dict:\n",
    "    poor_points = df_dict[key][['OBJECTID','geometry']]\n",
    "    sjoined = gpd.sjoin(poor_points, grid)\n",
    "    df_count = pd.DataFrame(sjoined.groupby('index_right').size()) \n",
    "    grid_join = grid.join(df_count)\n",
    "    grid[key] = grid_join[0]\n",
    "\n",
    "grid.int_prim[np.isnan(grid.int_prim)] = 0.0   \n",
    "grid.int_prim_sec[np.isnan(grid.int_prim_sec)] = 0.0   \n",
    "grid.int_sec[np.isnan(grid.int_sec)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['int_prim','int_prim_sec','int_sec']] = np.nan   \n",
    "grid[['int_prim','int_prim_sec','int_sec']] = grid[['int_prim','int_prim_sec','int_sec']]/cell_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2bbad",
   "metadata": {},
   "source": [
    "**Line layers** considered:\n",
    "1. Highways\n",
    "2. Primary roads\n",
    "3. Secondary roads\n",
    "\n",
    "Input reference system EPSG: 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3982ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_path = cwd + '/road_infrastructures/highway.gpkg'\n",
    "prim_road_path = cwd + '/road_infrastructures/prim_road.gpkg'\n",
    "sec_road_path = cwd + '/road_infrastructures/sec_road.gpkg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65d645",
   "metadata": {},
   "source": [
    "Converted to EPSG:32632 for length calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway = gpd.read_file(highway_path).to_crs(32632)\n",
    "prim_road = gpd.read_file(prim_road_path).to_crs(32632)\n",
    "sec_road = gpd.read_file(sec_road_path).to_crs(32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f090893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'highway':highway, 'prim_road':prim_road, 'sec_road':sec_road}\n",
    "\n",
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_lines = df_dict[key][['geodb_oid','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_lines, mask) \n",
    "        l = clip.geometry.length.sum()\n",
    "        grid[key].iloc[index] = l*m_to_km\n",
    "    print(key)\n",
    "\n",
    "grid.highway[np.isnan(grid.highway)] = 0.0   \n",
    "grid.prim_road[np.isnan(grid.prim_road)] = 0.0   \n",
    "grid.sec_road[np.isnan(grid.sec_road)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['highway','prim_road','sec_road']] = np.nan  \n",
    "grid[['highway','prim_road','sec_road']] = grid[['highway','prim_road','sec_road']]/cell_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386ff5e",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8880917",
   "metadata": {},
   "source": [
    "### Farms\n",
    "Vector file obtained from DUSAF 2018 (features with cod. 12112 = \"Agricultural production settlements.\n",
    "This class includes buildings used for productive activities in the primary sector, such as sheds, machine sheds, barns, stables, silos, etc., together with accessory spaces. When these buildings are present together with residential buildings, forming a rural aggregate, if the two types cannot be clearly separated, the whole nucleus is classified as a farmstead (11231)\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "farms_path = cwd + '/farms/farms_dissolve.gpkg'\n",
    "farms = gpd.read_file(farms_path)\n",
    "\n",
    "df_dict2 = {'farms':farms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict2:\n",
    "    grid[key] = np.nan\n",
    "    poor_poly = df_dict2[key][['COD_TOT','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_poly, mask) \n",
    "        a = clip.geometry.area.sum()\n",
    "        grid[key].iloc[index] = a*m2_to_km2\n",
    "    print(\"Added column: \", key)\n",
    "    \n",
    "grid.farms[np.isnan(grid.farms)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['farms']] = np.nan  \n",
    "grid['farms'] = grid['farms']/cell_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b3d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.to_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1ae27",
   "metadata": {},
   "source": [
    "### Breeding farm type\n",
    "\n",
    "Breeding farm types available:\n",
    "1. Pigs\n",
    "2. Pultry\n",
    "3. Sheeps\n",
    "\n",
    "Accessible from: https://www.cartografia.servizirl.it/arcgis2/rest/services/agricoltura/Agricoltura/MapServer/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pigs_path = cwd + '/farms/pigs.gpkg'\n",
    "poultry_path = cwd + '/farms/poultry.gpkg'\n",
    "sheep_path = cwd + '/farms/sheep.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_pigs = gpd.read_file(pigs_path)\n",
    "farm_poultry = gpd.read_file(poultry_path)\n",
    "farm_sheep = gpd.read_file(sheep_path)\n",
    "\n",
    "df_dict = {'farm_pigs':farm_pigs,\n",
    "          'farm_poultry':farm_poultry, 'farm_sheep':farm_sheep}\n",
    "\n",
    "\n",
    "for key in df_dict:\n",
    "    poor_points = df_dict[key][['OBJECTID','geometry']]\n",
    "    sjoined = gpd.sjoin(poor_points, grid)\n",
    "    df_count = pd.DataFrame(sjoined.groupby('index_right').size()) \n",
    "    grid_join = grid.join(df_count)\n",
    "    grid[key] = grid_join[0]\n",
    "    print(key)\n",
    "    \n",
    "grid.farm_pigs[np.isnan(grid.farm_pigs)] = 0.0   \n",
    "grid.farm_poultry[np.isnan(grid.farm_poultry)] = 0.0   \n",
    "grid.farm_sheep[np.isnan(grid.farm_sheep)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['farm_pigs','farm_poultry','farm_sheep']] = np.nan   \n",
    "grid[['farm_pigs','farm_poultry','farm_sheep']] = grid[['farm_pigs','farm_poultry','farm_sheep']]/cell_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdc364",
   "metadata": {},
   "source": [
    "Create grid with Map Layers already preprocessed to avoid calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6170df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'grid_'+str(name.value)+\"_prep.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.to_crs(4326).to_file(cwd+\"/grid/\"+'grid_'+str(name.value)+\"_prep.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8fb9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9d27e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Satellite - Model - Ground Sensor <a id='not-map-layers'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93db235",
   "metadata": {},
   "source": [
    "In this section satellite, model and ground sensor data are imported. They are obtained from their specific processing notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb5a27",
   "metadata": {},
   "source": [
    "Import the Map Layers preprocessed version of the grid (\"prep\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gpd.read_file(cwd +\"/grid/\"+'grid_'+str(name.value)+\"_prep.gpkg\") #Read the preprocessed version grid (\"prep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad3cec",
   "metadata": {},
   "source": [
    "### NDVI \n",
    "NDVI obtained from [Terra Vegetation Indices 16-Day Global 250m dataset](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD13Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_path = cwd + '/temp/ndvi.tif'\n",
    "ndvi = rio.open(ndvi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_array = ndvi.read(1)\n",
    "affine = ndvi.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ndvi_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ndvi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744545b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbed27",
   "metadata": {},
   "source": [
    "### ECMWF - C3S ERA5 Model Meteorological data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a37245",
   "metadata": {},
   "source": [
    "Meteorological data are obtained from [ERA5 - Land Hourly Reanalysis](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY).\n",
    "The variables considered are: \n",
    "1. Temperature\n",
    "2. Precipitation\n",
    "3. Atmospheric pressure\n",
    "4. Wind speed (eastward and northward components)\n",
    "5. Soil humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "temp_2m_path = cwd + '/temp/temp_2m.tif'\n",
    "prec_path = cwd + '/temp/prec.tif'\n",
    "press_path = cwd + '/temp/press.tif'\n",
    "n_wind_path = cwd + '/temp/n_wind.tif'\n",
    "e_wind_path = cwd + '/temp/e_wind.tif'\n",
    "soil_moist_path = cwd + '/temp/soil_hum.tif'\n",
    "\n",
    "temp_2m = rio.open(temp_2m_path)\n",
    "prec = rio.open(prec_path)\n",
    "press = rio.open(press_path)\n",
    "n_wind = rio.open(n_wind_path)\n",
    "e_wind = rio.open(e_wind_path)\n",
    "soil_moist = rio.open(soil_moist_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2m_array = temp_2m.read(1)\n",
    "affine = temp_2m.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, temp_2m_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"temp_2m\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_array = prec.read(1)\n",
    "prec_array[prec_array<0]=np.nan\n",
    "affine = prec.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, prec_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"prec\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_array = press.read(1)\n",
    "press_array[press_array<0]=np.nan\n",
    "affine = press.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, press_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"press\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wind_array = n_wind.read(1)\n",
    "affine = n_wind.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, n_wind_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"n_wind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_wind_array = e_wind.read(1)\n",
    "affine = e_wind.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, e_wind_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"e_wind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6619-da07-42b0-b65a-072e81159abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_moist_array = soil_moist.read(1)\n",
    "soil_moist_array[soil_moist_array<0]=np.nan\n",
    "affine = soil_moist.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, soil_moist_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"soil_moist\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20540936",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import pollutants\n",
    "\n",
    "Importing pollutants data from:\n",
    "- Sentinel-5P Tropomi instrument and Terra&Aqua MODIS.\n",
    "- Copernicus Atmosphere Monitoring Service (CAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Sentinel-5P Tropomi and Terra&Aqua MODIS\n",
    "no2_path = cwd + '/temp/no2_s5p.tif'\n",
    "so2_path = cwd + '/temp/so2_s5p.tif'\n",
    "aod55_path = cwd + '/temp/aod_055.tif'\n",
    "aod47_path = cwd + '/temp/aod_047.tif'\n",
    "uvai_path = cwd + '/temp/uvai_s5p.tif'\n",
    "co_path = cwd + '/temp/co_s5p.tif'\n",
    "ch2o_path = cwd + '/temp/ch2o_s5p.tif'\n",
    "o3_path = cwd + '/temp/o3_s5p.tif'\n",
    "ch4_path = cwd + '/temp/ch4_s5p.tif'\n",
    "\n",
    "no2 = rio.open(no2_path)\n",
    "so2 = rio.open(so2_path)\n",
    "aod55 = rio.open(aod55_path)\n",
    "aod47 = rio.open(aod47_path)\n",
    "uvai = rio.open(uvai_path)\n",
    "co = rio.open(co_path)\n",
    "ch2o = rio.open(ch2o_path)\n",
    "o3 = rio.open(o3_path)\n",
    "ch4 = rio.open(ch4_path)\n",
    "#------------------------\n",
    "#From CAMS\n",
    "nh3_cams_path = cwd + '/temp/nh3_cams.nc'\n",
    "no_cams_path = cwd + '/temp/no_cams.nc'\n",
    "co_cams_path = cwd + '/temp/co_cams.nc'\n",
    "no2_cams_path = cwd + '/temp/no2_cams.nc'\n",
    "dust_cams_path = cwd + '/temp/dust_cams.nc'\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams.nc'\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams.nc'\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams.nc'\n",
    "so2_cams_path = cwd + '/temp/so2_cams.nc'\n",
    "o3_cams_path = cwd + '/temp/o3_cams.nc'\n",
    "\n",
    "nh3_cams = rioxarray.open_rasterio(nh3_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "no_cams = rioxarray.open_rasterio(no_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "co_cams = rioxarray.open_rasterio(co_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "no2_cams = rioxarray.open_rasterio(no2_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "dust_cams = rioxarray.open_rasterio(dust_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "pm10_cams = rioxarray.open_rasterio(pm10_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "pm25_cams = rioxarray.open_rasterio(pm25_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "nmvocs_cams = rioxarray.open_rasterio(nmvocs_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "so2_cams = rioxarray.open_rasterio(so2_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "o3_cams = rioxarray.open_rasterio(o3_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "#Convert nh3 to .tif\n",
    "nh3_cams.rio.to_raster(cwd + \"/temp/nh3_cams.tif\")\n",
    "nh3_cams_path = cwd + '/temp/nh3_cams.tif'\n",
    "nh3_cams = rio.open(nh3_cams_path)\n",
    "#Convert NO to .tif\n",
    "no_cams.rio.to_raster(cwd + \"/temp/no_cams.tif\")\n",
    "no_cams_path = cwd + '/temp/no_cams.tif'\n",
    "no_cams = rio.open(no_cams_path)\n",
    "#Convert CO to .tif\n",
    "co_cams.rio.to_raster(cwd + \"/temp/co_cams.tif\")\n",
    "co_cams_path = cwd + '/temp/co_cams.tif'\n",
    "co_cams = rio.open(co_cams_path)\n",
    "#Convert dust to .tif\n",
    "dust_cams.rio.to_raster(cwd + \"/temp/dust_cams.tif\")\n",
    "dust_cams_path = cwd + '/temp/dust_cams.tif'\n",
    "dust_cams = rio.open(dust_cams_path)\n",
    "#Convert pm10 to .tif\n",
    "pm10_cams.rio.to_raster(cwd + \"/temp/pm10_cams.tif\")\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams.tif'\n",
    "pm10_cams = rio.open(pm10_cams_path)\n",
    "#Convert pm25 to .tif\n",
    "pm25_cams.rio.to_raster(cwd + \"/temp/pm25_cams.tif\")\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams.tif'\n",
    "pm25_cams = rio.open(pm25_cams_path)\n",
    "#Convert NO2 to .tif\n",
    "no2_cams.rio.to_raster(cwd + \"/temp/no2_cams.tif\")\n",
    "no2_cams_path = cwd + '/temp/no2_cams.tif'\n",
    "no2_cams = rio.open(no2_cams_path)\n",
    "#Convert NMVOCs to .tif\n",
    "nmvocs_cams.rio.to_raster(cwd + \"/temp/nmvocs_cams.tif\")\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams.tif'\n",
    "nmvocs_cams = rio.open(nmvocs_cams_path)\n",
    "#Convert SO2 to .tif\n",
    "so2_cams.rio.to_raster(cwd + \"/temp/so2_cams.tif\")\n",
    "so2_cams_path = cwd + '/temp/so2_cams.tif'\n",
    "so2_cams = rio.open(so2_cams_path)\n",
    "#Convert o3 to .tif\n",
    "o3_cams.rio.to_raster(cwd + \"/temp/o3_cams.tif\")\n",
    "o3_cams_path = cwd + '/temp/o3_cams.tif'\n",
    "o3_cams = rio.open(o3_cams_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e27fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Satellite Data Processing\n",
    "Reading satellite .tif files with rasterio and calculating mean values for each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24512325",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_array = no2.read(1)\n",
    "no2_array[no2_array<=0]=np.nan\n",
    "affine = no2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_array = so2.read(1)\n",
    "so2_array[so2_array<=0]=np.nan\n",
    "affine = so2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, so2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15202a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "aod55_array = aod55.read(1)\n",
    "aod55_array[aod55_array<=0]=np.nan\n",
    "affine = aod55.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aod55_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aod_055\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5477913",
   "metadata": {},
   "outputs": [],
   "source": [
    "aod47_array = aod47.read(1)\n",
    "aod55_array[aod55_array<=0]=np.nan\n",
    "affine = aod47.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aod47_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aod_047\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvai_array = uvai.read(1)\n",
    "affine = uvai.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, uvai_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"uvai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca91553",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_array = co.read(1)\n",
    "co_array[co_array<=0]=np.nan\n",
    "affine = co.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, co_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0853c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2o_array = ch2o.read(1)\n",
    "ch2o_array[ch2o_array<=0]=np.nan\n",
    "affine = ch2o.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ch2o_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ch2o_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_array = o3.read(1)\n",
    "o3_array[o3_array<=0]=np.nan\n",
    "affine = o3.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, o3_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"o3_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch4_array = ch4.read(1)\n",
    "ch4_array[ch4_array<=0]=np.nan\n",
    "affine = ch4.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ch4_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ch4_s5p\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e69c1e",
   "metadata": {},
   "source": [
    "### [CAMS Model Air Quality Data](https://ads.atmosphere.copernicus.eu/cdsapp#!/dataset/cams-europe-air-quality-forecasts?tab=overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a1d38",
   "metadata": {},
   "source": [
    "Reading satellite .tif files with rasterio and calculating mean values for each cell. <br>\n",
    "CAMS data are provided with an original resolution of 0.1°. When the CAMS grid is selected, the upscale_factor is set to 1 and the data keep the original CAMS grid resolution.\n",
    "When a grid with a higher resolution is selected (s5p or arpa grid) CAMS data are interpolated to a higher resolution (upscale_factor > 1) to allow zonal statistics calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34074a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in os.listdir(cwd+'/temp'):\n",
    "    if files[-9:] == '_cams.tif':\n",
    "        file_name = files[:(len(files)-9)]\n",
    "        xds = rioxarray.open_rasterio(cwd + \"/temp/\"+files,masked=True)\n",
    "        new_width = xds.rio.width * upscale_factor\n",
    "        new_height = xds.rio.height * upscale_factor\n",
    "        xds_upsampled = xds.rio.reproject(xds.rio.crs,shape=(new_height, new_width),resampling=Resampling.bilinear)\n",
    "        xds_upsampled.rio.to_raster(cwd +'/temp/'+file_name+'_cams_upsampled.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMS data\n",
    "nh3_cams_path = cwd + '/temp/nh3_cams_upsampled.tif'\n",
    "nh3_cams = rio.open(nh3_cams_path)\n",
    "\n",
    "no_cams_path = cwd + '/temp/no_cams_upsampled.tif'\n",
    "no_cams = rio.open(no_cams_path)\n",
    "\n",
    "co_cams_path = cwd + '/temp/co_cams_upsampled.tif'\n",
    "co_cams = rio.open(co_cams_path)\n",
    "\n",
    "dust_cams_path = cwd + '/temp/dust_cams_upsampled.tif'\n",
    "dust_cams = rio.open(dust_cams_path)\n",
    "\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams_upsampled.tif'\n",
    "pm10_cams = rio.open(pm10_cams_path)\n",
    "\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams_upsampled.tif'\n",
    "pm25_cams = rio.open(pm25_cams_path)\n",
    "\n",
    "no2_cams_path = cwd + '/temp/no2_cams_upsampled.tif'\n",
    "no2_cams = rio.open(no2_cams_path)\n",
    "\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams_upsampled.tif'\n",
    "nmvocs_cams = rio.open(nmvocs_cams_path)\n",
    "\n",
    "so2_cams_path = cwd + '/temp/so2_cams_upsampled.tif'\n",
    "so2_cams = rio.open(so2_cams_path)\n",
    "\n",
    "o3_cams_path = cwd + '/temp/o3_cams_upsampled.tif'\n",
    "o3_cams = rio.open(o3_cams_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8023f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh3_cams_array = nh3_cams.read(1)\n",
    "nh3_cams_array[nh3_cams_array<0]=np.nan\n",
    "affine = nh3_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, nh3_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nh3_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211549e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cams_array = no_cams.read(1)\n",
    "no_cams_array[no_cams_array<0]=np.nan\n",
    "affine = no_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_cams_array = co_cams.read(1)\n",
    "co_cams_array[co_cams_array<0]=np.nan\n",
    "affine = co_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, co_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_cams_array = dust_cams.read(1)\n",
    "dust_cams_array[dust_cams_array<0]=np.nan\n",
    "affine = dust_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, dust_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"dust_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10_cams_array = pm10_cams.read(1)\n",
    "pm10_cams_array[pm10_cams_array<0]=np.nan\n",
    "affine = pm10_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pm10_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm10_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99060c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_cams_array = pm25_cams.read(1)\n",
    "pm25_cams_array[pm25_cams_array<0]=np.nan\n",
    "affine = pm25_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pm25_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm25_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_cams_array = no2_cams.read(1)\n",
    "no2_cams_array[no2_cams_array<0]=np.nan\n",
    "affine = no2_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no2_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184073b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmvocs_cams_array = nmvocs_cams.read(1)\n",
    "nmvocs_cams_array[nmvocs_cams_array<0]=np.nan\n",
    "affine = nmvocs_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, nmvocs_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nmvocs_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_cams_array = so2_cams.read(1)\n",
    "so2_cams_array[so2_cams_array<0]=np.nan\n",
    "affine = so2_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, so2_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_cams_array = o3_cams.read(1)\n",
    "o3_cams_array[o3_cams_array<0]=np.nan\n",
    "affine = o3_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, o3_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"o3_cams\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df332d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe26885",
   "metadata": {},
   "source": [
    "### Meteo stations - Point layer\n",
    "Importing multipoint geometry, where each point contains mean values for each sensor type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st_path = cwd + '/temp/temp_st.gpkg'\n",
    "prec_st_path = cwd + '/temp/prec_st.gpkg'\n",
    "air_hum_st_path = cwd + '/temp/air_hum_st.gpkg'\n",
    "wind_dir_st_path = cwd + '/temp/wind_dir_st.gpkg'\n",
    "wind_speed_st_path = cwd + '/temp/wind_speed_st.gpkg'\n",
    "rad_glob_st_path = cwd + '/temp/rad_glob_st.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda99bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st = gpd.read_file(temp_st_path)\n",
    "prec_st = gpd.read_file(prec_st_path)\n",
    "air_hum_st = gpd.read_file(air_hum_st_path)\n",
    "wind_dir_st = gpd.read_file(wind_dir_st_path)\n",
    "wind_speed_st = gpd.read_file(wind_speed_st_path)\n",
    "rad_glob_st = gpd.read_file(rad_glob_st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'temp_st':temp_st,\n",
    "          'prec_st':prec_st, 'air_hum_st': air_hum_st, 'wind_dir_st':wind_dir_st, 'wind_speed_st':wind_speed_st,\n",
    "          'rad_glob_st':rad_glob_st}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            clip = gpd.clip(poor_points, mask)\n",
    "            m = clip.valore.mean()\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881cb3",
   "metadata": {},
   "source": [
    "### Air quality stations - Point layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87185d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st_path = cwd + '/temp/pm25_st.gpkg'\n",
    "nox_st_path = cwd + '/temp/nox_st.gpkg'\n",
    "no2_st_path = cwd + '/temp/no2_st.gpkg'\n",
    "nh3_st_path = cwd + '/temp/nh3_st.gpkg'\n",
    "so2_st_path = cwd + '/temp/so2_st.gpkg'\n",
    "pm10_st_path = cwd + '/temp/pm10_st.gpkg'\n",
    "co_st_path = cwd + '/temp/co_st.gpkg'\n",
    "o3_st_path = cwd + '/temp/o3_st.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st = gpd.read_file(pm25_st_path)\n",
    "nox_st = gpd.read_file(nox_st_path)\n",
    "no2_st = gpd.read_file(no2_st_path)\n",
    "nh3_st = gpd.read_file(nh3_st_path)\n",
    "so2_st = gpd.read_file(so2_st_path)\n",
    "pm10_st = gpd.read_file(pm10_st_path)\n",
    "co_st = gpd.read_file(co_st_path)\n",
    "o3_st = gpd.read_file(o3_st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'pm25_st':pm25_st,\n",
    "          'nox_st':nox_st, 'no2_st': no2_st,'o3_st':o3_st, 'nh3_st':nh3_st, 'so2_st':so2_st, 'pm10_st':pm10_st, 'co_st':co_st}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = 0\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            mask = row['geometry']\n",
    "            clip = gpd.clip(poor_points, mask) \n",
    "            m = clip.valore.mean()\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc862760",
   "metadata": {},
   "source": [
    "### Import Low Cost Sensor data ([ESA Air Quality Sensors](https://aqp.eo.esa.int/map/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_lcs_path = cwd + '/temp/pm25_lcs.gpkg'\n",
    "pm10_lcs_path = cwd + '/temp/pm10_lcs.gpkg'\n",
    "hum_lcs_path = cwd + '/temp/hum_lcs.gpkg'\n",
    "temp_lcs_path = cwd + '/temp/temp_lcs.gpkg'\n",
    "no2_lcs_path = cwd + '/temp/no2_lcs.gpkg'\n",
    "co2_lcs_path = cwd + '/temp/co2_lcs.gpkg'\n",
    "nh3_lcs_path = cwd + '/temp/nh3_lcs.gpkg'\n",
    "co_lcs_path = cwd + '/temp/co_lcs.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36385537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_lcs = gpd.read_file(pm25_lcs_path)\n",
    "pm10_lcs = gpd.read_file(pm10_lcs_path)\n",
    "hum_lcs = gpd.read_file(hum_lcs_path)\n",
    "temp_lcs = gpd.read_file(temp_lcs_path)\n",
    "no2_lcs = gpd.read_file(no2_lcs_path)\n",
    "co2_lcs = gpd.read_file(co2_lcs_path)\n",
    "nh3_lcs = gpd.read_file(nh3_lcs_path)\n",
    "co_lcs = gpd.read_file(co_lcs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'pm25_lcs':pm25_lcs,\n",
    "          'pm10_lcs':pm10_lcs, 'hum_lcs': hum_lcs, 'temp_lcs':temp_lcs, 'no2_lcs':no2_lcs,\n",
    "          'co2_lcs':co2_lcs, 'nh3_lcs':nh3_lcs, 'co_lcs':co_lcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = 0\n",
    "    poor_points = df_dict[key][['device_id','value','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            mask = row['geometry']\n",
    "            clip = gpd.clip(poor_points, mask) \n",
    "            m = clip.value.mean()\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501367c",
   "metadata": {},
   "source": [
    "### Air quality data from station interpolated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.to_crs(32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "int_co_path = cwd + '/temp/int_co.tif'\n",
    "int_nh3_path = cwd + '/temp/int_nh3.tif'\n",
    "int_no2_path = cwd + '/temp/int_no2.tif'\n",
    "int_nox_path = cwd + '/temp/int_nox.tif'\n",
    "int_o3_path = cwd + '/temp/int_o3.tif'\n",
    "int_pm10_path = cwd + '/temp/int_pm10.tif'\n",
    "int_pm25_path = cwd + '/temp/int_pm25.tif'\n",
    "int_so2_path = cwd + '/temp/int_so2.tif'\n",
    "\n",
    "int_co = rio.open(int_co_path)\n",
    "int_nh3 = rio.open(int_nh3_path)\n",
    "int_no2 = rio.open(int_no2_path)\n",
    "int_nox = rio.open(int_nox_path)\n",
    "int_o3 = rio.open(int_o3_path)\n",
    "int_pm10 = rio.open(int_pm10_path)\n",
    "int_pm25 = rio.open(int_pm25_path)\n",
    "int_so2 = rio.open(int_so2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72eddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_co_array = int_co.read(1).astype('float64') \n",
    "affine = int_co.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_co_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65014e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_nh3_array = int_nh3.read(1).astype('float64') \n",
    "affine = int_nh3.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_nh3_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nh3_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_no2_array = int_no2.read(1).astype('float64') \n",
    "affine = int_no2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_no2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe47f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_nox_array = int_nox.read(1).astype('float64') \n",
    "affine = int_nox.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_nox_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nox_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_o3_array = int_o3.read(1).astype('float64') \n",
    "affine = int_o3.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_o3_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"o3_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pm10_array = int_pm10.read(1).astype('float64') \n",
    "affine = int_pm10.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_pm10_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm10_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pm25_array = int_pm25.read(1).astype('float64') \n",
    "affine = int_pm25.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_pm25_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm25_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_so2_array = int_so2.read(1).astype('float64') \n",
    "affine = int_so2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_so2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_int\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4145fdd",
   "metadata": {},
   "source": [
    "### Meteorological data from station interpolated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2608ef7",
   "metadata": {},
   "source": [
    "In order to get continuous data over the Lombardy region, interpolated ground sensor data are used. For precipitation data, interpolated values below 0 mm/h are set to 0 mm/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "int_air_hum_path = cwd + '/temp/int_air_hum.tif'\n",
    "int_prec_path = cwd + '/temp/int_prec.tif'\n",
    "int_rad_glob_path = cwd + '/temp/int_rad_glob.tif'\n",
    "int_temp_path = cwd + '/temp/int_temp.tif'\n",
    "int_wind_dir_path = cwd + '/temp/int_wind_dir.tif'\n",
    "int_wind_speed_path = cwd + '/temp/int_wind_speed.tif'\n",
    "\n",
    "\n",
    "int_air_hum = rio.open(int_air_hum_path)\n",
    "int_prec = rio.open(int_prec_path)\n",
    "int_rad_glob = rio.open(int_rad_glob_path)\n",
    "int_temp = rio.open(int_temp_path)\n",
    "int_wind_dir = rio.open(int_wind_dir_path)\n",
    "int_wind_speed = rio.open(int_wind_speed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_air_hum_array = int_air_hum.read(1).astype('float64') \n",
    "affine = int_air_hum.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_air_hum_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"air_hum_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658464a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_prec_array = int_prec.read(1).astype('float64') \n",
    "int_prec_array[int_prec_array<0]=0  #set values to 0 if interpolation is negative\n",
    "affine = int_prec.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_prec_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"prec_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5385ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rad_glob_array = int_rad_glob.read(1).astype('float64') \n",
    "affine = int_rad_glob.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_rad_glob_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"rad_glob_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_temp_array = int_temp.read(1).astype('float64') \n",
    "affine = int_temp.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_temp_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"temp_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a859054",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_wind_dir_array = int_wind_dir.read(1).astype('float64') \n",
    "affine = int_wind_dir.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_wind_dir_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"wind_dir_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb65962",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_wind_speed_array = int_wind_speed.read(1).astype('float64') \n",
    "affine = int_wind_speed.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_wind_speed_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"wind_speed_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85b26b-7382-4641-87fc-f65bc2729026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = grid.drop(columns=['air_hum_int','prec_int','rad_glob_int','temp_int',\"wind_dir_int\",\"wind_speed_int\",\"co_int\",\"nh3_int\",\"no2_int\",\"nox_int\",\"o3_int\",\"pm10_int\",\"pm25_int\",\"so2_int\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53154a27-0cd9-4b32-a016-fd8c1a06e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_air_hum.close()\n",
    "# int_prec.close()\n",
    "# int_rad_glob.close()\n",
    "# int_temp.close()\n",
    "# int_wind_dir.close()\n",
    "# int_wind_speed.close()\n",
    "# int_co.close()\n",
    "# int_nh3.close()\n",
    "# int_no2.close()\n",
    "# int_nox.close()\n",
    "# int_o3.close()\n",
    "# int_pm10.close()\n",
    "# int_pm25.close()\n",
    "# int_so2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb45f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## File export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef79c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(grid) #list of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805844b",
   "metadata": {},
   "source": [
    "Grid name: for example grid_cams_0310_0317_2021 corresponds to the grid with:\n",
    "- CAMS grid resolution\n",
    "- Start and end date (mmdd) for which the average are calculated (for example 0310 is March 10th and 0317 is March 17th). \n",
    "- 2021 year of calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225aace-6e07-4b42-bb1a-1f1f3e7ea001",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_notna = grid[grid['aq_zone'].notna()]  #remove rows where aq_zone is nan (outside lombardy region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_name = ''.join(str(i)+'_' for i in custom_week).replace('-','')\n",
    "date_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = 'grid_'+str(name.value)+'_'+date_name.replace('-','')+str(year)\n",
    "print(\"The exported file name: \", grid_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d0320",
   "metadata": {},
   "source": [
    "Export the file with WGS84 CRS setting the grid name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff491b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_notna.to_crs(4326).to_file(cwd+\"/results/\"+grid_name+\"kk.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd579e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa1e00-90db-47b2-80ce-3f796751c943",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c4b40-1473-44fa-b9a9-e525aae5d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa2880-cadb-4130-ae68-ab0f8376c62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cont = widgets.Dropdown(\n",
    "    options=col_list,\n",
    "    value=col_list[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def plot(m):    \n",
    "    grid_notna.plot(column = cont.value, figsize=(20, 10), legend=True)\n",
    "out = widgets.interactive_output(plot, {'m': cont})\n",
    "widgets.VBox([widgets.HBox([cont]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4ca2f-30aa-483f-9b2b-ddd306aa61fc",
   "metadata": {},
   "source": [
    "### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fddbd-3082-472b-ae7e-77fb8848925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter(feature1, feature2):\n",
    "    with plt.style.context(\"ggplot\"):\n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        plt.scatter(x = grid[feature1], y = grid[feature2], s=20)\n",
    "        \n",
    "        plt.xlabel(feature1)\n",
    "        plt.ylabel(feature2)\n",
    "        plt.title(\"%s vs %s\"%(feature1, feature2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34720a0c-b7e0-4577-8912-52ae391a69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = widgets.Dropdown(\n",
    "    options=col_list,\n",
    "    value=col_list[0],\n",
    "    description='X:',\n",
    "    disabled=False,\n",
    ")\n",
    "feature2 = widgets.Dropdown(\n",
    "    options=col_list,\n",
    "    value=col_list[0],\n",
    "    description='Y:',\n",
    "    disabled=False,\n",
    ")\n",
    "out = widgets.interactive_output(create_scatter, {'feature1': feature1, 'feature2':feature2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e22d1-b31e-4bb5-ad81-5fcfb24325a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.VBox([widgets.HBox([feature1, feature2]), out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6d083-be78-45ca-8300-53c84ced05c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e52b0-c6f9-49a7-9ed2-6bcfdee77a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
