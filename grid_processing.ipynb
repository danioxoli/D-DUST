{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a595331",
   "metadata": {},
   "source": [
    "# D-DUST Data Grid Processing Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf9ee1d",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b5dae",
   "metadata": {},
   "source": [
    "Check the following link for Data Management Plan and the Variable list table: <br>\n",
    "**1. [Data Management Plan (DMP)](https://docs.google.com/document/d/1n3PVat7PBTG76JnINOkL2pvBZuKQlakZkTgqNj39oAQ/edit#)**<br>\n",
    "**2. [Variables list table](https://docs.google.com/spreadsheets/d/1-5pwMSc1QlFyC8iIaA-l1fWhWtpqVio2/edit#gid=91313358)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6f2f5",
   "metadata": {},
   "source": [
    "This notebook describes the physical variables selected for the project and how they are preprocessed.\n",
    "These variables are divided into <u>4 categories</u>, as shown in the Variable list table:\n",
    "1. **Map Layer**: static layer used to describe Lombardy region morphology and its features (such as elevation, infrastructures, land use and cover etc.)\n",
    "2. **Model**: data retrieved from a model that uses satellite and in-situ observations of meteorological and air quality data as input (such as ERA5, CAMS).\n",
    "3. **Satellite**: data obtained directly from satellite observations (such as Sentinel-5P).\n",
    "4. **Ground Sensor**: data retrieved from ground monitoring stations measuring air quality and meteorological variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da51273",
   "metadata": {},
   "source": [
    "First the other notebooks must be used in order to retrieve all the data in the same time range.\n",
    "- GEE_API Notebook: satellite images + ERA5 data\n",
    "- ADS_API Copernicus Notebook: ADS data from CAMS analysis model\n",
    "- ARPA_API Ground Sensors Notebook: data from ARPA ground sensor\n",
    "- AQ_ESA Stations Notebook: data from ESA Air Quality station\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0316e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff716c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import scipy.interpolate\n",
    "from scipy.interpolate import griddata\n",
    "import rasterstats as rstat\n",
    "import rioxarray\n",
    "import shapely.speedups\n",
    "shapely.speedups.enable()\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import  MultiLineString\n",
    "from rasterio.enums import Resampling\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5319ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import select_grid as sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "405957a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972837ff",
   "metadata": {},
   "source": [
    "## Import grids\n",
    "\n",
    "Three grids with different spatial resolution are used in this project:\n",
    "1. **cams** grid: 0.1° x 0.1° resolution - Grid with CAMS Model spatial resolution.\n",
    "2. **s5p** grid: 0.066° x 0.066° resolution - Grid with the Sentinel-5P approximate spatial resolution.\n",
    "3. **arpa** grid: 0.01° x 0.01° resolution- Grid generated with at most one ARPA monitoring station for each pixel.\n",
    "\n",
    "These grids are defined as bounding box of the Lombardy region layer applying a buffer of 20 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf62a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337826a2c88643209551826860e54cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='name:', options=('cams', 's5p', 'arpa'), value='cams')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# With this widget is possible to select from the dropdown list\n",
    "name = widgets.Dropdown(\n",
    "    options=['cams', 's5p', 'arpa'],\n",
    "    description='name:',\n",
    "    disabled=False)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265cc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to interpolate CAMS .tif file with a lower resolution depending on the grid cell size (useful for zonal statistics)\n",
    "if name.value == 'cams':\n",
    "    upscale_factor = 1  \n",
    "if name.value == 's5p':\n",
    "    upscale_factor = 10\n",
    "if name.value == 'arpa':\n",
    "    upscale_factor = 10  \n",
    "\n",
    "grid_path = sg.select_grid(name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d8a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gpd.read_file(cwd + grid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23482afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_to_km = 10**(-3)\n",
    "m2_to_km2 = 10**(-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02584c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479eb93",
   "metadata": {},
   "source": [
    "# Importing Map Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc4356",
   "metadata": {},
   "source": [
    "### [DUSAF - Land use - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B18EE7CDC-E51B-4DFB-99F8-3CF416FC3C70%7D) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe9826",
   "metadata": {},
   "source": [
    "Consists in a multi-temporal geographic database that classifies land based on major land cover and land use types. Reference system EPSG:4326.<br>\n",
    "Land use:\n",
    "- 2 = Aree agricole.\n",
    "- 3 =Territori boscati e ambienti seminaturali.\n",
    "- 4 = Aree umide.\n",
    "- 5 = Corpi idrici.\n",
    "- 11 = Zone urbanizzate.\n",
    "- 12 = Insediamenti produttivo, grandi impianti e reti di comunicazione.\n",
    "- 13 = Aree estrattive, discariche, cantieri, terreni artefatti e abbandonati.\n",
    "- 14 = Aree verdi non agricole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fb8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dusaf_path = cwd + '/land_use_cover/DUSAF6_dissolve_rast_4326.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a13eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dusaf = rio.open(dusaf_path)\n",
    "dusaf_array = dusaf.read(1).astype('float64') \n",
    "dusaf_array[dusaf_array<1.0]=np.nan\n",
    "affine = dusaf.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b3a5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats = rstat.zonal_stats(grid, dusaf_array, affine=affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"dusaf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fb2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats = rstat.zonal_stats(grid, dusaf_array, affine=affine, nodata=np.nan, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats, orient='columns')\n",
    "p = p*m2_to_km2\n",
    "\n",
    "grid['dsf2'] = p[2.0]\n",
    "grid['dsf3'] = p[3.0]\n",
    "grid['dsf4'] = p[4.0]\n",
    "grid['dsf5'] = p[5.0]\n",
    "grid['dsf11'] = p[11.0]\n",
    "grid['dsf12'] = p[12.0]\n",
    "grid['dsf13'] = p[13.0]\n",
    "grid['dsf14'] = p[14.0]\n",
    "grid['dsfSum'] = p['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba17ce",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b2e46",
   "metadata": {},
   "source": [
    "### [SIARL - Agricultural use - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B83483117-8742-4A1F-A16E-3A48AEE2EBE2%7D) <br>\n",
    "This layer contains the agricoltural use for each cadastral parcel provided by SIARL 2019 Catalog for the Lombardy region. Reference system EPSG:4326. <br>\n",
    "Agricoltural use:\n",
    "- 2 Altri cereali\n",
    "- 7 Foraggere\n",
    "- 9 Mais\n",
    "- 12 Riso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b49d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "siarl_path = cwd + '/land_use_cover/siarl.tif'\n",
    "siarl = rio.open(siarl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a2089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "siarl_array = siarl.read(1).astype('float64') \n",
    "siarl_array[siarl_array<1.0]=np.nan\n",
    "affine = siarl.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198dee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_siarl = rstat.zonal_stats(grid, siarl_array, affine=affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_siarl]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"siarl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f2819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_siarl = rstat.zonal_stats(grid, siarl_array, affine=affine, nodata=np.nan, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_siarl, orient='columns')\n",
    "p = p*m2_to_km2\n",
    "\n",
    "grid['siarl2'] = p[2.0]\n",
    "grid['siarl7'] = p[7.0]\n",
    "grid['siarl9'] = p[9.0]\n",
    "grid['siarl12'] = p[12.0]\n",
    "\n",
    "grid['siarlSum'] = p['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe2abe",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2bfc48",
   "metadata": {},
   "source": [
    "### [Digital Terrain Model - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7BFC06681A-2403-481F-B6FE-5F952DD48BAF%7D)<br>\n",
    "Digital Terrain Model of Lombardy region with 20 m resolution. Reference system EPSG:4326.\n",
    "1. **Elevation** = DTM with 20 m resolution\n",
    "2. **Aspect** = calculated previously from the elevation layer\n",
    "3. **Slope** = calculated previously from the elevation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b80a33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_path = cwd + '/terrain/dtm20.tif'\n",
    "aspect_path = cwd + '/terrain/aspect.tif'\n",
    "slope_path = cwd + '/terrain/slope.tif'\n",
    "dtm = rio.open(dtm_path)\n",
    "aspect = rio.open(aspect_path)\n",
    "slope = rio.open(slope_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75b9d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for the elevation\n",
    "dtm_array = dtm.read(1)\n",
    "dtm_array[dtm_array<0]=np.nan\n",
    "affine = dtm.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, dtm_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"h_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b7924f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for aspect\n",
    "aspect_array = aspect.read(1)\n",
    "aspect_array[aspect_array<0]=np.nan\n",
    "affine = aspect.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aspect_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aspect_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16d494fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for slope\n",
    "slope_array = slope.read(1)\n",
    "slope_array[slope_array<0]=np.nan\n",
    "affine = slope.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, slope_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"slope_mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74615632",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9011a5",
   "metadata": {},
   "source": [
    "### Soil and Vegetation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f95e87",
   "metadata": {},
   "source": [
    "In this part information concerning soil and vegetation is considered, such as:\n",
    "- Soil type: classification fron OpenLandMap soil classification\n",
    "- Soil text: classification obtained from (Carta Pedologica 1:250.000) from Geoportale Regione Lombardia\n",
    "- Soil moist: soil moisture in soil layer 1 (0 - 7 cm) of the ECMWF Integrated Forecasting System\n",
    "- NDVI: NDVI obtained from Terra Vegetation Indices 16-Day Global 250m dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbf7ca2",
   "metadata": {},
   "source": [
    "USDA Soil Classification (missing value 3, 10, 12 in this Lombardy region): \n",
    "- 1 Clay\n",
    "- 2 Silty Clay\n",
    "- 3 Sandy Clay\n",
    "- 4 Clay Loeam\n",
    "- 5 Silty Clay Loam\n",
    "- 6 Sandy Clay Loam\n",
    "- 7 Loam\n",
    "- 8 Silt Loam\n",
    "- 9 Sandy Loam\n",
    "- 10 Silt\n",
    "- 11 Loamy Sand\n",
    "- 12 Sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d94d4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_type_path = cwd + '/temp/soil_type.tif'\n",
    "soil_moist_path = cwd + '/temp/soil_hum.tif'\n",
    "ndvi_path = cwd + '/temp/ndvi.tif'\n",
    "soil_text_path = cwd + '/temp/carta_pedologica_4326_dissolved_250K.tif'\n",
    "\n",
    "soil_type = rio.open(soil_type_path)\n",
    "soil_moist = rio.open(soil_moist_path)\n",
    "ndvi = rio.open(ndvi_path)\n",
    "soil_text = rio.open(soil_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330ac883",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_type_array = soil_type.read(1).astype('float64') \n",
    "soil_type_array[soil_type_array<1.0]=np.nan\n",
    "affine = soil_type.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cead2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_soil_type = rstat.zonal_stats(grid, soil_type_array, affine=affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_soil_type]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"soil\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14d72647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_soil = rstat.zonal_stats(grid, soil_type_array, affine=affine, nodata=np.nan, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_soil, orient='columns')\n",
    "grid['soil1'] = p[1.0]\n",
    "grid['soil2'] = p[2.0]\n",
    "#grid['soil3'] = p[3.0] #not present in lombardy region .tif\n",
    "grid['soil4'] = p[4.0]\n",
    "grid['soil5'] = p[5.0]\n",
    "grid['soil6'] = p[6.0]\n",
    "grid['soil7'] = p[7.0]\n",
    "grid['soil8'] = p[8.0]\n",
    "grid['soil9'] = p[9.0]\n",
    "#grid['soil10'] = p[10.0] #not present in lombardy region .tif\n",
    "grid['soil11'] = p[11.0]\n",
    "#grid['soil12'] = p[12.0] #not present in lombardy region .tif\n",
    "\n",
    "grid['soilSum'] = p['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436c1da",
   "metadata": {},
   "source": [
    "Soil texture type:\n",
    "- 1 Argillosa fine\n",
    "- 2 Argillosa molto fine\n",
    "- 3 Franca fine\n",
    "- 4 Franca grossolana\n",
    "- 5 Limosa fine\n",
    "- 6 Limosa grossolana\n",
    "- 7 Sabbiosa\n",
    "- 8 Scheletrico-Argillosa\n",
    "- 9 Scheletrico-Franca\n",
    "- 10 Scheletrico-Sabbiosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32ae2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_text_array = soil_text.read(1).astype('float64') \n",
    "soil_text_array[soil_text_array<1.0]=np.nan\n",
    "affine = soil_text.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86513bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_soil_text = rstat.zonal_stats(grid, soil_text_array, affine=affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_soil_text]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"soil_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb4bfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class counts in each tile\n",
    "stats_soil_text = rstat.zonal_stats(grid, soil_text_array, affine=affine, nodata=np.nan, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_soil_text, orient='columns')\n",
    "grid['soil_text1'] = p[1.0]\n",
    "grid['soil_text2'] = p[2.0]\n",
    "grid['soil_text3'] = p[3.0]\n",
    "grid['soil_text4'] = p[4.0]\n",
    "grid['soil_text5'] = p[5.0]\n",
    "grid['soil_text6'] = p[6.0]\n",
    "grid['soil_text7'] = p[7.0]\n",
    "grid['soil_text8'] = p[8.0]\n",
    "grid['soil_text9'] = p[9.0]\n",
    "grid['soil_text10'] = p[10.0]\n",
    "\n",
    "grid['soilTextSum'] = p['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4f655e",
   "metadata": {},
   "source": [
    "Soil Moisture from ERA5 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac4fd347",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_moist_array = soil_moist.read(1)\n",
    "affine = soil_moist.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, soil_moist_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"soil_moist\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad3cec",
   "metadata": {},
   "source": [
    "NDVI from MODIS 16-days global:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd43a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_array = ndvi.read(1)\n",
    "affine = ndvi.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ndvi_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ndvi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744545b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbed27",
   "metadata": {},
   "source": [
    "### Import climate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6db859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths for temperature at 2m level, precipitation and ndvi\n",
    "temp_2m_path = cwd + '/temp/temp_2m.tif'\n",
    "prec_path = cwd + '/temp/prec.tif'\n",
    "press_path = cwd + '/temp/press.tif'\n",
    "n_wind_path = cwd + '/temp/n_wind.tif'\n",
    "e_wind_path = cwd + '/temp/e_wind.tif'\n",
    "\n",
    "temp_2m = rio.open(temp_2m_path)\n",
    "prec = rio.open(prec_path)\n",
    "press = rio.open(press_path)\n",
    "n_wind = rio.open(n_wind_path)\n",
    "e_wind = rio.open(e_wind_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f694798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2m_array = temp_2m.read(1)\n",
    "affine = temp_2m.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, temp_2m_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"temp_2m\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7232c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_array = prec.read(1)\n",
    "prec_array[prec_array<0]=np.nan\n",
    "affine = prec.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, prec_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"prec\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a2f787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_array = press.read(1)\n",
    "press_array[press_array<0]=np.nan\n",
    "affine = press.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, press_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"press\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4cfe3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wind_array = n_wind.read(1)\n",
    "affine = n_wind.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, n_wind_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"n_wind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9a9930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_wind_array = e_wind.read(1)\n",
    "affine = e_wind.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, e_wind_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"e_wind\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20540936",
   "metadata": {},
   "source": [
    "### Import pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "325b17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From S5P\n",
    "no2_path = cwd + '/temp/no2.tif'\n",
    "so2_path = cwd + '/temp/so2.tif'\n",
    "aod55_path = cwd + '/temp/aod_055.tif'\n",
    "aod47_path = cwd + '/temp/aod_047.tif'\n",
    "uvai_path = cwd + '/temp/uvai.tif'\n",
    "co_path = cwd + '/temp/co.tif'\n",
    "form_path = cwd + '/temp/form.tif'\n",
    "ozone_path = cwd + '/temp/ozone.tif'\n",
    "\n",
    "no2 = rio.open(no2_path)\n",
    "so2 = rio.open(so2_path)\n",
    "aod55 = rio.open(aod55_path)\n",
    "aod47 = rio.open(aod47_path)\n",
    "uvai = rio.open(uvai_path)\n",
    "co = rio.open(co_path)\n",
    "form = rio.open(form_path)\n",
    "ozone = rio.open(ozone_path)\n",
    "\n",
    "#From CAMS\n",
    "amm_cams_path = cwd + '/temp/amm_cams.nc'\n",
    "no_cams_path = cwd + '/temp/no_cams.nc'\n",
    "co_cams_path = cwd + '/temp/co_cams.nc'\n",
    "no2_cams_path = cwd + '/temp/no2_cams.nc'\n",
    "dust_cams_path = cwd + '/temp/dust_cams.nc'\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams.nc'\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams.nc'\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams.nc'\n",
    "so2_cams_path = cwd + '/temp/so2_cams.nc'\n",
    "ozone_cams_path = cwd + '/temp/ozone_cams.nc'\n",
    "\n",
    "amm_cams = rioxarray.open_rasterio(amm_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "no_cams = rioxarray.open_rasterio(no_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "co_cams = rioxarray.open_rasterio(co_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "no2_cams = rioxarray.open_rasterio(no2_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "dust_cams = rioxarray.open_rasterio(dust_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "pm10_cams = rioxarray.open_rasterio(pm10_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "pm25_cams = rioxarray.open_rasterio(pm25_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "nmvocs_cams = rioxarray.open_rasterio(nmvocs_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "so2_cams = rioxarray.open_rasterio(so2_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "ozone_cams = rioxarray.open_rasterio(ozone_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "#Convert ammonia to .tif\n",
    "amm_cams.rio.to_raster(cwd + \"/temp/amm_cams.tif\")\n",
    "amm_cams_path = cwd + '/temp/amm_cams.tif'\n",
    "amm_cams = rio.open(amm_cams_path)\n",
    "#Convert NO to .tif\n",
    "no_cams.rio.to_raster(cwd + \"/temp/no_cams.tif\")\n",
    "no_cams_path = cwd + '/temp/no_cams.tif'\n",
    "no_cams = rio.open(no_cams_path)\n",
    "#Convert CO to .tif\n",
    "co_cams.rio.to_raster(cwd + \"/temp/co_cams.tif\")\n",
    "co_cams_path = cwd + '/temp/co_cams.tif'\n",
    "co_cams = rio.open(co_cams_path)\n",
    "#Convert dust to .tif\n",
    "dust_cams.rio.to_raster(cwd + \"/temp/dust_cams.tif\")\n",
    "dust_cams_path = cwd + '/temp/dust_cams.tif'\n",
    "dust_cams = rio.open(dust_cams_path)\n",
    "#Convert pm10 to .tif\n",
    "pm10_cams.rio.to_raster(cwd + \"/temp/pm10_cams.tif\")\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams.tif'\n",
    "pm10_cams = rio.open(pm10_cams_path)\n",
    "#Convert pm25 to .tif\n",
    "pm25_cams.rio.to_raster(cwd + \"/temp/pm25_cams.tif\")\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams.tif'\n",
    "pm25_cams = rio.open(pm25_cams_path)\n",
    "#Convert NO2 to .tif\n",
    "no2_cams.rio.to_raster(cwd + \"/temp/no2_cams.tif\")\n",
    "no2_cams_path = cwd + '/temp/no2_cams.tif'\n",
    "no2_cams = rio.open(no2_cams_path)\n",
    "#Convert NMVOCs to .tif\n",
    "nmvocs_cams.rio.to_raster(cwd + \"/temp/nmvocs_cams.tif\")\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams.tif'\n",
    "nmvocs_cams = rio.open(nmvocs_cams_path)\n",
    "#Convert SO2 to .tif\n",
    "so2_cams.rio.to_raster(cwd + \"/temp/so2_cams.tif\")\n",
    "so2_cams_path = cwd + '/temp/so2_cams.tif'\n",
    "so2_cams = rio.open(so2_cams_path)\n",
    "#Convert Ozone to .tif\n",
    "ozone_cams.rio.to_raster(cwd + \"/temp/ozone_cams.tif\")\n",
    "ozone_cams_path = cwd + '/temp/ozone_cams.tif'\n",
    "ozone_cams = rio.open(ozone_cams_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e27fa",
   "metadata": {},
   "source": [
    "### Sentinel-5P Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24512325",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_array = no2.read(1)\n",
    "affine = no2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad7659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_array = so2.read(1)\n",
    "affine = so2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, so2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15202a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "aod55_array = aod55.read(1)\n",
    "affine = aod55.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aod55_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aod_055\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5477913",
   "metadata": {},
   "outputs": [],
   "source": [
    "aod47_array = aod47.read(1)\n",
    "affine = aod47.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aod47_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aod_047\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92f2d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvai_array = uvai.read(1)\n",
    "affine = uvai.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, uvai_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"uvai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aca91553",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_array = co.read(1)\n",
    "affine = co.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, co_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d0853c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "form_array = form.read(1)\n",
    "affine = form.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, form_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"form_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "370d8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone_array = ozone.read(1)\n",
    "affine = ozone.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ozone_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ozone_s5p\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e69c1e",
   "metadata": {},
   "source": [
    "### CAMS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a1d38",
   "metadata": {},
   "source": [
    "Resample CAMS data (original resolution 0.1°): zonal stats has issues with original resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34074a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in os.listdir(cwd+'/temp'):\n",
    "    if files[-9:] == '_cams.tif':\n",
    "        file_name = files[:(len(files)-9)]\n",
    "        xds = rioxarray.open_rasterio(cwd + \"/temp/\"+files,masked=True)\n",
    "        new_width = xds.rio.width * upscale_factor\n",
    "        new_height = xds.rio.height * upscale_factor\n",
    "        xds_upsampled = xds.rio.reproject(xds.rio.crs,shape=(new_height, new_width),resampling=Resampling.bilinear)\n",
    "        xds_upsampled.rio.to_raster(cwd +'/temp/'+file_name+'_cams_upsampled.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df1c0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "amm_cams_path = cwd + '/temp/amm_cams_upsampled.tif'\n",
    "amm_cams = rio.open(amm_cams_path)\n",
    "\n",
    "no_cams_path = cwd + '/temp/no_cams_upsampled.tif'\n",
    "no_cams = rio.open(no_cams_path)\n",
    "\n",
    "co_cams_path = cwd + '/temp/co_cams_upsampled.tif'\n",
    "co_cams = rio.open(co_cams_path)\n",
    "\n",
    "dust_cams_path = cwd + '/temp/dust_cams_upsampled.tif'\n",
    "dust_cams = rio.open(dust_cams_path)\n",
    "\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams_upsampled.tif'\n",
    "pm10_cams = rio.open(pm10_cams_path)\n",
    "\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams_upsampled.tif'\n",
    "pm25_cams = rio.open(pm25_cams_path)\n",
    "\n",
    "no2_cams_path = cwd + '/temp/no2_cams_upsampled.tif'\n",
    "no2_cams = rio.open(no2_cams_path)\n",
    "\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams_upsampled.tif'\n",
    "nmvocs_cams = rio.open(nmvocs_cams_path)\n",
    "\n",
    "so2_cams_path = cwd + '/temp/so2_cams_upsampled.tif'\n",
    "so2_cams = rio.open(so2_cams_path)\n",
    "\n",
    "ozone_cams_path = cwd + '/temp/ozone_cams_upsampled.tif'\n",
    "ozone_cams = rio.open(ozone_cams_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8023f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "amm_cams_array = amm_cams.read(1)\n",
    "affine = amm_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, amm_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"amm_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "211549e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cams_array = no_cams.read(1)\n",
    "affine = no_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72cbfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_cams_array = co_cams.read(1)\n",
    "affine = co_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, co_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bea7ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_cams_array = dust_cams.read(1)\n",
    "affine = dust_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, dust_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"dust_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f04d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10_cams_array = pm10_cams.read(1)\n",
    "affine = pm10_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pm10_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm10_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99060c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_cams_array = pm25_cams.read(1)\n",
    "affine = pm25_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pm25_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm25_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47ba7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_cams_array = no2_cams.read(1)\n",
    "affine = no2_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no2_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "184073b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmvocs_cams_array = nmvocs_cams.read(1)\n",
    "affine = nmvocs_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, nmvocs_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nmvocs_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "234c1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_cams_array = so2_cams.read(1)\n",
    "affine = so2_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, so2_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c43d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone_cams_array = ozone_cams.read(1)\n",
    "affine = ozone_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ozone_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ozone_cams\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa1b51",
   "metadata": {},
   "source": [
    "### [Gridded Population of the World - GPW](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11)<br>\n",
    "To provide estimates of population density for the year 2020, based on counts consistent with national censuses and population registers, as raster data to facilitate data integration.\n",
    "Input reference system EPSG: 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50824464",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_path = cwd + '/population/population.tif'\n",
    "pop = rio.open(pop_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81549559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_array = pop.read(1)\n",
    "pop_array[pop_array<0]=np.nan\n",
    "affine = pop.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pop_array, affine=affine, nodata=np.nan, stats=['sum'])), how='left')\n",
    "grid = grid.rename(columns={\"sum\": \"pop\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63274bc",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abbb74",
   "metadata": {},
   "source": [
    "### [Road Infrastructures - Geoportale Lombardia (DBTR 2019)](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B17D4656F-2E9D-4951-9DC1-4AD32C0959B1%7D): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce0a36",
   "metadata": {},
   "source": [
    "**Point layers** considered:\n",
    "1. Intersection between primary roads including highways\n",
    "2. Intersection between primary and secondary roads\n",
    "3. Intersection between secondary roads\n",
    "\n",
    "Input reference system EPSG: 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "baa4954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_prim_path = cwd + '/road_infrastructures/inters_highway_prim_road.gpkg'\n",
    "int_prim_sec_path = cwd + '/road_infrastructures/inters_prim_sec_road.gpkg'\n",
    "int_sec_path = cwd + '/road_infrastructures/inters_sec_road.gpkg'\n",
    "\n",
    "grid = grid.to_crs(32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "82dfe4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_prim = gpd.read_file(int_prim_path).to_crs(32632)\n",
    "int_prim_sec = gpd.read_file(int_prim_sec_path).to_crs(32632)\n",
    "int_sec = gpd.read_file(int_sec_path).to_crs(32632)\n",
    "\n",
    "df_dict = {'int_prim':int_prim,\n",
    "          'int_prim_sec':int_prim_sec, 'int_sec': int_sec}\n",
    "\n",
    "\n",
    "for key in df_dict:\n",
    "    poor_points = df_dict[key][['OBJECTID','geometry']]\n",
    "    sjoined = gpd.sjoin(poor_points, grid)\n",
    "    df_count = pd.DataFrame(sjoined.groupby('index_right').size()) \n",
    "    grid_join = grid.join(df_count)\n",
    "    grid[key] = grid_join[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2bbad",
   "metadata": {},
   "source": [
    "**Line layers** considered:\n",
    "1. Highways\n",
    "2. Primary roads\n",
    "3. Secondary roads\n",
    "\n",
    "Input reference system EPSG: 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c3982ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_path = cwd + '/road_infrastructures/highway.gpkg'\n",
    "prim_road_path = cwd + '/road_infrastructures/prim_road.gpkg'\n",
    "sec_road_path = cwd + '/road_infrastructures/sec_road.gpkg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da65d645",
   "metadata": {},
   "source": [
    "It is required to convert to a cartographic reference system EPSG:32632 to calculate distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e1c2b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "highway = gpd.read_file(highway_path).to_crs(32632)\n",
    "prim_road = gpd.read_file(prim_road_path).to_crs(32632)\n",
    "sec_road = gpd.read_file(sec_road_path).to_crs(32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f090893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highway\n",
      "prim_road\n",
      "sec_road\n"
     ]
    }
   ],
   "source": [
    "df_dict = {'highway':highway, 'prim_road':prim_road, 'sec_road':sec_road}\n",
    "\n",
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_lines = df_dict[key][['geodb_oid','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_lines, mask) \n",
    "        l = clip.geometry.length.sum()\n",
    "        grid[key].iloc[index] = l*m_to_km\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386ff5e",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8880917",
   "metadata": {},
   "source": [
    "### Farms\n",
    "Vector file obtained from DUSAF 2018 (features with cod. 12112 = \"Insediamenti produttivi agricoli\n",
    "Sono compresi in questa classe gli edifici utilizzati per le attività produttive del settore primario, come capannoni, rimesse per macchine agricole, fienili, stalle, silos, ecc, unitamente agli spazi accessori. Quando tali edifici sono presenti insieme a quelli residenziali configurando un aggregato rurale, se le due tipologie non risultano separabili in modo evidente si classifica tutto il nucleo come cascina (11231)\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b7f63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "farms_path = cwd + '/farms/farms_dissolve.gpkg'\n",
    "farms = gpd.read_file(farms_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bf7a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict2 = {'farms':farms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc1bec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "farms\n"
     ]
    }
   ],
   "source": [
    "for key in df_dict2:\n",
    "    grid[key] = np.nan\n",
    "    poor_poly = df_dict2[key][['COD_TOT','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_poly, mask) \n",
    "        a = clip.geometry.area.sum()\n",
    "        grid[key].iloc[index] = a*m2_to_km2\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2b3d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.to_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1ae27",
   "metadata": {},
   "source": [
    "### Breeding farm type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3bc3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pigs_path = cwd + '/farms/pigs.gpkg'\n",
    "poultry_path = cwd + '/farms/poultry.gpkg'\n",
    "sheep_path = cwd + '/farms/sheep.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22ffb704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "farm_pigs\n",
      "farm_poultry\n",
      "farm_sheep\n"
     ]
    }
   ],
   "source": [
    "farm_pigs = gpd.read_file(pigs_path)\n",
    "farm_poultry = gpd.read_file(poultry_path)\n",
    "farm_sheep = gpd.read_file(sheep_path)\n",
    "\n",
    "df_dict = {'farm_pigs':farm_pigs,\n",
    "          'farm_poultry':farm_poultry, 'farm_sheep':farm_sheep}\n",
    "\n",
    "\n",
    "for key in df_dict:\n",
    "    poor_points = df_dict[key][['OBJECTID','geometry']]\n",
    "    sjoined = gpd.sjoin(poor_points, grid)\n",
    "    df_count = pd.DataFrame(sjoined.groupby('index_right').size()) \n",
    "    grid_join = grid.join(df_count)\n",
    "    grid[key] = grid_join[0]\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df332d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a106b19",
   "metadata": {},
   "source": [
    "# Import air quality and meteo stations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f8653",
   "metadata": {},
   "source": [
    "Assign to each cell the value measured by each sensor. If more sensors of the same type are present in the same cell it assign the mean value:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe26885",
   "metadata": {},
   "source": [
    "### Meteo stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17d5a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st_path = cwd + '/temp/temp_st.gpkg'\n",
    "prec_st_path = cwd + '/temp/prec_st.gpkg'\n",
    "air_hum_st_path = cwd + '/temp/air_hum_st.gpkg'\n",
    "wind_dir_st_path = cwd + '/temp/wind_dir_st.gpkg'\n",
    "wind_speed_st_path = cwd + '/temp/wind_speed_st.gpkg'\n",
    "rad_glob_st_path = cwd + '/temp/rad_glob_st.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dda99bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st = gpd.read_file(temp_st_path)\n",
    "prec_st = gpd.read_file(prec_st_path)\n",
    "air_hum_st = gpd.read_file(air_hum_st_path)\n",
    "wind_dir_st = gpd.read_file(wind_dir_st_path)\n",
    "wind_speed_st = gpd.read_file(wind_speed_st_path)\n",
    "rad_glob_st = gpd.read_file(rad_glob_st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "08b7b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'temp_st':temp_st,\n",
    "          'prec_st':prec_st, 'air_hum_st': air_hum_st, 'wind_dir_st':wind_dir_st, 'wind_speed_st':wind_speed_st,\n",
    "          'rad_glob_st':rad_glob_st}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb2d0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_st\n",
      "prec_st\n",
      "air_hum_st\n",
      "wind_dir_st\n",
      "wind_speed_st\n",
      "rad_glob_st\n"
     ]
    }
   ],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_points, mask) \n",
    "        m = clip.valore.mean()\n",
    "        grid[key].iloc[index] = m\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881cb3",
   "metadata": {},
   "source": [
    "### Air quality station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "87185d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st_path = cwd + '/temp/pm25_st.gpkg'\n",
    "nox_st_path = cwd + '/temp/nox_st.gpkg'\n",
    "no2_st_path = cwd + '/temp/no2_st.gpkg'\n",
    "amm_st_path = cwd + '/temp/amm_st.gpkg'\n",
    "so2_st_path = cwd + '/temp/so2_st.gpkg'\n",
    "pm10_st_path = cwd + '/temp/pm10_st.gpkg'\n",
    "co_st_path = cwd + '/temp/co_st.gpkg'\n",
    "ozone_st_path = cwd + '/temp/o3_st.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "268a0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st = gpd.read_file(pm25_st_path)\n",
    "nox_st = gpd.read_file(nox_st_path)\n",
    "no2_st = gpd.read_file(no2_st_path)\n",
    "amm_st = gpd.read_file(amm_st_path)\n",
    "so2_st = gpd.read_file(so2_st_path)\n",
    "pm10_st = gpd.read_file(pm10_st_path)\n",
    "co_st = gpd.read_file(co_st_path)\n",
    "ozone_st = gpd.read_file(ozone_st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60ec521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'pm25_st':pm25_st,\n",
    "          'nox_st':nox_st, 'no2_st': no2_st,'ozone_st':ozone_st, 'amm_st':amm_st, 'so2_st':so2_st, 'pm10_st':pm10_st, 'co_st':co_st}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "90efa965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm25_st\n",
      "nox_st\n",
      "no2_st\n",
      "ozone_st\n",
      "amm_st\n",
      "so2_st\n",
      "pm10_st\n",
      "co_st\n"
     ]
    }
   ],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = 0\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_points, mask) \n",
    "        m = clip.valore.mean()\n",
    "        grid[key].iloc[index] = m\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc862760",
   "metadata": {},
   "source": [
    "### Import Low Cost Sensor data ([ESA Air Quality Sensors](https://aqp.eo.esa.int/map/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "38ffdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_lcs_path = cwd + '/temp/pm25_lcs.gpkg'\n",
    "pm10_lcs_path = cwd + '/temp/pm10_lcs.gpkg'\n",
    "hum_lcs_path = cwd + '/temp/hum_lcs.gpkg'\n",
    "temp_lcs_path = cwd + '/temp/temp_lcs.gpkg'\n",
    "no2_lcs_path = cwd + '/temp/no2_lcs.gpkg'\n",
    "co2_lcs_path = cwd + '/temp/co2_lcs.gpkg'\n",
    "amm_lcs_path = cwd + '/temp/amm_lcs.gpkg'\n",
    "co_lcs_path = cwd + '/temp/co_lcs.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36385537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_lcs = gpd.read_file(pm25_lcs_path)\n",
    "pm10_lcs = gpd.read_file(pm10_lcs_path)\n",
    "hum_lcs = gpd.read_file(hum_lcs_path)\n",
    "temp_lcs = gpd.read_file(temp_lcs_path)\n",
    "no2_lcs = gpd.read_file(no2_lcs_path)\n",
    "co2_lcs = gpd.read_file(co2_lcs_path)\n",
    "amm_lcs = gpd.read_file(amm_lcs_path)\n",
    "co_lcs = gpd.read_file(co_lcs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f4e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'pm25_lcs':pm25_lcs,\n",
    "          'pm10_lcs':pm10_lcs, 'hum_lcs': hum_lcs, 'temp_lcs':temp_lcs, 'no2_lcs':no2_lcs,\n",
    "          'co2_lcs':co2_lcs, 'amm_lcs':amm_lcs, 'co_lcs':co_lcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "beddd7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm25_lcs\n",
      "pm10_lcs\n",
      "hum_lcs\n",
      "temp_lcs\n",
      "no2_lcs\n",
      "co2_lcs\n",
      "amm_lcs\n",
      "co_lcs\n"
     ]
    }
   ],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = 0\n",
    "    poor_points = df_dict[key][['device_id','value','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_points, mask) \n",
    "        m = clip.value.mean()\n",
    "        grid[key].iloc[index] = m\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501367c",
   "metadata": {},
   "source": [
    "### Import air quality and meteorological data from station interpolated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324bdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72eddb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5820a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c5d0320",
   "metadata": {},
   "source": [
    "Export the file in WGS84:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dff491b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.to_crs(4326).to_file(cwd+\"/results/test_farm_grid.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "89427c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = grid.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "219907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.to_csv('prova.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141bd80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e15767c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9fb754f",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d85a3",
   "metadata": {},
   "source": [
    "Use a .tif raster (for example aod_055.tif) file to get the parameters for the interpolated raster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "acba0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aod = gdal.Open(cwd+\"/temp/aod_055.tif\")\n",
    "# gt = aod.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bcddfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ulx = gt[0]\n",
    "# uly = gt[3]\n",
    "# res = gt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "76b1c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xsize = aod.RasterXSize\n",
    "# ysize = aod.RasterYSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "920f3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lrx = ulx + xsize * res\n",
    "# lry = uly - ysize * res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2aea5017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rRes = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53fe2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lon= air_hum_st['lng']\n",
    "# lat =air_hum_st['lat']\n",
    "# value = air_hum_st['valore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8ba1d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xRange = np.arange(ulx,lrx+rRes,rRes)\n",
    "# yRange = np.arange(lry,uly+rRes,rRes)\n",
    "# gridX,gridY = np.meshgrid(xRange, yRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f2b4d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK = OrdinaryKriging(lon, lat, value,\n",
    "#                      variogram_model='gaussian', verbose=True, enable_plotting=False,nlags=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "deba05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(OrdinaryKriging.__doc__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b61843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridded, ss1 = OK.execute('grid', xRange, yRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "777d3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(gridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6844e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rasterio.transform import Affine\n",
    "# transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes,rRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66ffed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rasterio.crs import CRS\n",
    "# rasterCrs = CRS.from_epsg(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9d492f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #definition, register and close of interpolated raster\n",
    "# interpRaster = rio.open(cwd+'/kriging.tif',\n",
    "#                                 'w',\n",
    "#                                 driver='GTiff',\n",
    "#                                 height=gridded.shape[0],\n",
    "#                                 width=gridded.shape[1],\n",
    "#                                 count=1,\n",
    "#                                 nodata = -9999,\n",
    "#                                 dtype=gridded.dtype,\n",
    "#                                 crs=rasterCrs,\n",
    "#                                 transform=transform,\n",
    "#                                 )\n",
    "# interpRaster.write(gridded, 1)\n",
    "# interpRaster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb6d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ccb1b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts = ogr.Open(cwd+'/temp/air_hum_st.gpkg', update = True)\n",
    "# layer=pts.GetLayer()\n",
    "\n",
    "# to generate a an interpolation using GDAL library\n",
    "# pts = layer = None\n",
    "# idw = gdal.Grid(\"idw.tif\", (cwd+'/temp/air_hum_st.gpkg'), zfield=\"valore\",\n",
    "#                algorithm = \"invdist\", outputBounds = [ulx,uly,lrx,lry],\n",
    "#                width = xsize, height = ysize)\n",
    "# idw = None\n",
    "\n",
    "# points = list(zip(air_hum_st.lng,air_hum_st.lat))\n",
    "\n",
    "# gridded = griddata(points, value, (gridX,gridY), method='linear',fill_value=0)\n",
    "\n",
    "# gridded = gridded.reshape((gridded.shape[0], gridded.shape[1]))\n",
    "\n",
    "# plt.imshow(gridded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
