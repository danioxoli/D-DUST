{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1c351c",
   "metadata": {},
   "source": [
    "# ARPA Lombardia Ground Sensors data request notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30092cc6",
   "metadata": {},
   "source": [
    "This notebook is used to download data from both meteorological and air quality ground sensor of ARPA Lombardia network segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d050786",
   "metadata": {},
   "source": [
    "In detail, each sensor type, position and time serie are retrieved as it follows:\n",
    "- Ground sensor's type and position is always retrived through the ARPA API: [Air quality stations](https://www.dati.lombardia.it/Ambiente/Stazioni-qualit-dell-aria/ib47-atvt) and [Meteorological stations](https://www.dati.lombardia.it/Ambiente/Stazioni-Meteorologiche/nf78-nj6b)\n",
    "- Time series are available through API request for the current year only (e.g. from Jenuary 2022) for both [Air quality data](https://www.dati.lombardia.it/Ambiente/Dati-sensori-aria/nicp-bhqi) and  [Meteorological data](https://www.dati.lombardia.it/Ambiente/Dati-sensori-meteo/647i-nhxk). (this may change in future).\n",
    "- To use data from previous years it's required to use the dataset in .csv format, such as [Air quality data for 2020]( https://www.dati.lombardia.it/Ambiente/Dati-sensori-aria-2020/88sp-5tmj) or [Meteorological data for 2020](https://www.dati.lombardia.it/Ambiente/Dati-sensori-meteo-2020/erjn-istm). The **ARPA_URL_by_year** function contains the links to .csv data for each year. to allow automatic download and preprocessing.\n",
    "\n",
    "In this notebook sensors position and types are retrieved from the API only, while time series can retreived by .csv or API depending on the decided year (if before 2022 is only possible to use the .csv file, while for 2022 data from API are available)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70063a78",
   "metadata": {},
   "source": [
    "At the end of the notebook there is a function where ground sensor data interpolation is performed using Radial Basis Function (RBF) method (from [Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.Rbf.html) library) over the region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613745f5",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "ARPA data a from API are accessible using [Socrata Open Data API](https://dev.socrata.com/). <br>\n",
    "The library [sodapy](https://github.com/xmunoz/sodapy) is a python client for the Socrata Open Data API.\n",
    "The \"app_token\" is required to access the data. <br>\n",
    "Example video tutorial: https://www.youtube.com/watch?v=3p4gncGaSeg&t=899s&ab_channel=CharmingData <br>\n",
    "Register on \"Open Data Lombardia\" to get tokens: https://www.dati.lombardia.it/login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a976f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feaa305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sodapy import Socrata\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import json\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current working directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5290f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import my_methods  #function where each year is associated to the resource link (for downloading the .csv file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489fe353",
   "metadata": {},
   "source": [
    "Modify **date.json** file to change the date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4ef9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = open('date.json')\n",
    "date = json.load(d)\n",
    "year = date['year']\n",
    "mais_week = date['mais_week']\n",
    "rice_week = date['rice_week']\n",
    "cereal_week = date['cereal_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c97fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = my_methods.manuring_periods(year, mais_week, rice_week, cereal_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9820617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this widget is possible to select from the dropdown list the required week\n",
    "select_week = widgets.Dropdown(\n",
    "    options=['mais_week', 'rice_week', 'cereal_week'],\n",
    "    description='name:',\n",
    "    disabled=False)\n",
    "select_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select start and end date of the corresponding selected week using data from .csv files:\n",
    "start_date = calendar[date[select_week.value][0]][0]\n",
    "end_date = calendar[date[select_week.value][-1]][-1]\n",
    "print(\"For\", select_week.value, \"the starting date is\", start_date,\"and the ending date is\" , end_date)\n",
    "start_date_dt = datetime.strptime(calendar[date[select_week.value][0]][0], '%Y-%m-%d')\n",
    "end_date_dt = datetime.strptime(calendar[date[select_week.value][-1]][-1], '%Y-%m-%d')+timedelta(days=1) #increase 1 day to select data from arpa sensor correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b394f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = str(start_date_dt)[0:10]\n",
    "end_date = str(end_date_dt)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f735fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_object = datetime.strptime(start_date, '%Y-%m-%d').date()\n",
    "year = str(date_object.year) #select the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f4b1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use only for current year data request using API (data for years different from current one are not available)\n",
    "# start_date_api = '\"2022-01-01\"'\n",
    "# end_date_api = '\"2022-01-03\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d72903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key and app token for Socrata API\n",
    "f = open('keys.json')\n",
    "keys = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37dc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f3b09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc69c0f",
   "metadata": {},
   "source": [
    "# Import stations and sensor type from ARPA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d6fe9",
   "metadata": {},
   "source": [
    "Import sensors description and position from the API: https://www.dati.lombardia.it/Ambiente/Stazioni-qualit-dell-aria/ib47-atvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada35c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_domain = \"www.dati.lombardia.it\"\n",
    "st_descr = \"ib47-atvt\"\n",
    "\n",
    "client = Socrata(arpa_domain, app_token = keys['arpa_token']) \n",
    "results = client.get_all(st_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_st_descr = pd.DataFrame(results)\n",
    "air_st_descr[\"idsensore\"] = air_st_descr[\"idsensore\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cebc2c0",
   "metadata": {},
   "source": [
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463d807",
   "metadata": {},
   "source": [
    "<a id='aq_data_api'></a>\n",
    "# Import air quality data from ARPA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b54908",
   "metadata": {},
   "source": [
    "Skip to [air quality import from .csv](#aq_data_csv) data if required. The API works for current year data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6bfcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_domain = \"www.dati.lombardia.it\"\n",
    "dati = \"nicp-bhqi\" #change this depending on the dataset (check Open Data Lombardia datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d10471",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(arpa_domain, app_token = \"riTLzYVRVdDaQtUkxDDaHRgJi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea80e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_query = \"data > {} and data < {}\".format(start_date_api,end_date_api)\n",
    "date_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5165b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.get(dati, where=date_query, limit=5000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb575d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data['data'] =  pd.to_datetime(aq_data['data'], format='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data = aq_data.astype({\"idsensore\": int,\"valore\": float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b1012",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50fd38",
   "metadata": {},
   "source": [
    "<a id='aq_data_csv'></a>\n",
    "# Import air quality data from .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a0cc1",
   "metadata": {},
   "source": [
    "Go back to [air quality import from API](#aq_data_api) data if required. Used to access data from past years (not current one)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e11cf3",
   "metadata": {},
   "source": [
    "Example using air quality data 2020 from ARPA stations: https://www.dati.lombardia.it/Ambiente/Dati-sensori-aria-2020/88sp-5tmj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223695e0",
   "metadata": {},
   "source": [
    "Download the .csv data for the selected year in a zip folder. Read the .csv file and put it in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bda550",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = my_methods.AQ_sensor(year)\n",
    "r = requests.get(csv_url, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_zip = open('aq_'+str(year)+'.zip', 'wb').write(r.content)\n",
    "archive = zipfile.ZipFile('aq_'+str(year)+'.zip', 'r')\n",
    "data = archive.open(str(year)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data=pd.read_csv(data)\n",
    "aq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe75ea4",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data.rename(columns={'IdSensore': 'idsensore','Data': 'data','idOperatore': 'idoperatore','Stato': 'stato','Valore': 'valore'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a044d34",
   "metadata": {},
   "source": [
    "Set date format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data['data'] =  pd.to_datetime(aq_data['data'], format='%d/%m/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d631c3fc",
   "metadata": {},
   "source": [
    "Select date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (aq_data.data >= start_date) & (aq_data.data <= end_date)\n",
    "aq_data = aq_data.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20742d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a97b0",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe9e011",
   "metadata": {},
   "source": [
    "# Air quality data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f68f9",
   "metadata": {},
   "source": [
    "Drop \"stato\" and \"idoperatore\" columns and select valid values different from -9999:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec42686",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_data = aq_data.drop(columns=['stato', 'idoperatore'])\n",
    "aq_data = aq_data[aq_data.valore.astype(float) != -9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af98ca",
   "metadata": {},
   "source": [
    "Get the unique sensor type names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ad095",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_st_descr.nometiposensore.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_sel = ['Ossidi di Azoto', 'Monossido di Carbonio', 'Biossido di Azoto','Ozono',\n",
    "       'Biossido di Zolfo', 'Particelle sospese PM2.5','Ammoniaca','PM10 (SM2005)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5f022",
   "metadata": {},
   "source": [
    "Join sensors description and information with the mean value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_table = pd.merge(aq_data, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b38e5b",
   "metadata": {},
   "source": [
    "Select sensors adding their names to the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4d1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_table['nometiposensore'].astype(str)\n",
    "aq_table = aq_table[aq_table['nometiposensore'].isin(sensor_sel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st = aq_table.loc[aq_table['nometiposensore'] == 'Particelle sospese PM2.5']\n",
    "co_st = aq_table.loc[aq_table['nometiposensore'] == 'Monossido di Carbonio']\n",
    "no2_st = aq_table.loc[aq_table['nometiposensore'] == 'Biossido di Azoto']\n",
    "so2_st = aq_table.loc[aq_table['nometiposensore'] == 'Biossido di Zolfo']\n",
    "nh3_st = aq_table.loc[aq_table['nometiposensore'] == 'Ammoniaca']\n",
    "nox_st = aq_table.loc[aq_table['nometiposensore'] == 'Ossidi di Azoto']\n",
    "pm10_st = aq_table.loc[aq_table['nometiposensore'] == 'PM10 (SM2005)']\n",
    "o3_st = aq_table.loc[aq_table['nometiposensore'] == 'Ozono']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3e87c3",
   "metadata": {},
   "source": [
    "Z-Test to remove outliers and calculate mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f1f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st['zscore'] = np.abs(stats.zscore(pm25_st['valore'], nan_policy='propagate'))\n",
    "pm25_st = pm25_st[pm25_st.zscore < threshold]\n",
    "pm25_st = pm25_st.groupby(['idsensore'],as_index=False).mean()\n",
    "pm25_st = pd.merge(pm25_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d74657",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_st['zscore'] = np.abs(stats.zscore(co_st['valore'], nan_policy='propagate'))\n",
    "co_st = co_st[co_st.zscore < threshold]\n",
    "co_st = co_st.groupby(['idsensore'],as_index=False).mean()\n",
    "co_st = pd.merge(co_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fd8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_st['zscore'] = np.abs(stats.zscore(no2_st['valore'], nan_policy='propagate'))\n",
    "no2_st = no2_st[no2_st.zscore < threshold]\n",
    "no2_st = no2_st.groupby(['idsensore'],as_index=False).mean()\n",
    "no2_st = pd.merge(no2_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e77d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_st['zscore'] = np.abs(stats.zscore(so2_st['valore'], nan_policy='propagate'))\n",
    "so2_st = so2_st[so2_st.zscore < threshold]\n",
    "so2_st = so2_st.groupby(['idsensore'],as_index=False).mean()\n",
    "so2_st = pd.merge(so2_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da90f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh3_st['zscore'] = np.abs(stats.zscore(nh3_st['valore'], nan_policy='propagate'))\n",
    "nh3_st = nh3_st[nh3_st.zscore < threshold]\n",
    "nh3_st = nh3_st.groupby(['idsensore'],as_index=False).mean()\n",
    "nh3_st = pd.merge(nh3_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c4e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nox_st['zscore'] = np.abs(stats.zscore(nox_st['valore'], nan_policy='propagate'))\n",
    "nox_st = nox_st[nox_st.zscore < threshold]\n",
    "nox_st = nox_st.groupby(['idsensore'],as_index=False).mean()\n",
    "nox_st = pd.merge(nox_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10_st['zscore'] = np.abs(stats.zscore(pm10_st['valore'], nan_policy='propagate'))\n",
    "pm10_st = pm10_st[pm10_st.zscore < threshold]\n",
    "pm10_st = pm10_st.groupby(['idsensore'],as_index=False).mean()\n",
    "pm10_st = pd.merge(pm10_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2500d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_st['zscore'] = np.abs(stats.zscore(o3_st['valore'], nan_policy='propagate'))\n",
    "o3_st = o3_st[o3_st.zscore < threshold]\n",
    "o3_st = o3_st.groupby(['idsensore'],as_index=False).mean()\n",
    "o3_st = pd.merge(o3_st, air_st_descr, on='idsensore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305ba7c",
   "metadata": {},
   "source": [
    "Save sensors separately and create a .gpkg file for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_gdf = gpd.GeoDataFrame(pm25_st, geometry=gpd.points_from_xy(pm25_st.lng, pm25_st.lat))\n",
    "pm25_gdf = pm25_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc00511",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_gdf = gpd.GeoDataFrame(co_st, geometry=gpd.points_from_xy(co_st.lng, co_st.lat))\n",
    "co_gdf = co_gdf.set_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111d3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_gdf = gpd.GeoDataFrame(no2_st, geometry=gpd.points_from_xy(no2_st.lng, no2_st.lat))\n",
    "no2_gdf = no2_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ed0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_gdf = gpd.GeoDataFrame(so2_st, geometry=gpd.points_from_xy(so2_st.lng, so2_st.lat))\n",
    "so2_gdf = so2_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0781c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh3_gdf = gpd.GeoDataFrame(nh3_st, geometry=gpd.points_from_xy(nh3_st.lng, nh3_st.lat))\n",
    "nh3_gdf = nh3_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96436f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nox_gdf = gpd.GeoDataFrame(nox_st, geometry=gpd.points_from_xy(nox_st.lng, nox_st.lat))\n",
    "nox_gdf = nox_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ba68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10_gdf = gpd.GeoDataFrame(pm10_st, geometry=gpd.points_from_xy(pm10_st.lng, pm10_st.lat))\n",
    "pm10_gdf = pm10_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4fb661",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_gdf = gpd.GeoDataFrame(o3_st, geometry=gpd.points_from_xy(o3_st.lng, o3_st.lat))\n",
    "o3_gdf = o3_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d21aca7",
   "metadata": {},
   "source": [
    "Create a **temp** folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_gdf.to_file(cwd+\"/temp/pm25_st.gpkg\", driver=\"GPKG\")\n",
    "co_gdf.to_file(cwd+\"/temp/co_st.gpkg\", driver=\"GPKG\")\n",
    "no2_gdf.to_file(cwd+\"/temp/no2_st.gpkg\", driver=\"GPKG\")\n",
    "so2_gdf.to_file(cwd+\"/temp/so2_st.gpkg\", driver=\"GPKG\")\n",
    "nh3_gdf.to_file(cwd+\"/temp/nh3_st.gpkg\", driver=\"GPKG\")\n",
    "nox_gdf.to_file(cwd+\"/temp/nox_st.gpkg\", driver=\"GPKG\")\n",
    "pm10_gdf.to_file(cwd+\"/temp/pm10_st.gpkg\", driver=\"GPKG\")\n",
    "o3_gdf.to_file(cwd+\"/temp/o3_st.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc23d6a",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2ef3a",
   "metadata": {},
   "source": [
    "# Import meteorological stations from ARPA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f837e094",
   "metadata": {},
   "source": [
    "https://www.dati.lombardia.it/Ambiente/Dati-sensori-meteo-2020/erjn-istm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_domain = \"www.dati.lombardia.it\"\n",
    "m_st_descr = \"nf78-nj6b\"\n",
    "client = Socrata(arpa_domain, app_token = \"riTLzYVRVdDaQtUkxDDaHRgJi\")\n",
    "results = client.get_all(m_st_descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bca28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_st_descr = pd.DataFrame(results)\n",
    "meteo_st_descr[\"idsensore\"] = meteo_st_descr[\"idsensore\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbe952",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_st_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4079674",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724551c",
   "metadata": {},
   "source": [
    "<a id='meteo_data_api'></a>\n",
    "# Import meteorological data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0363cc",
   "metadata": {},
   "source": [
    "Skip to [meteorological data import from .csv](#meteo_data_csv) data if required. The API works for current month data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arpa_domain = \"www.dati.lombardia.it\"\n",
    "dati = \"647i-nhxk\" #change this depending on the dataset (check Open Data Lombardia datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14645551",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Socrata(arpa_domain, app_token = keys['arpa_token']) #insert your arpa_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536714ff",
   "metadata": {},
   "source": [
    "The date must be changed from the following request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c101e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_query = \"data > {} and data < {}\".format(start_date_api,end_date_api)\n",
    "date_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = client.get(dati, where=date_query, limit=5000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef26eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data['data'] =  pd.to_datetime(meteo_data['data'], format='%Y/%m/%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f368dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data = meteo_data.astype({\"idsensore\": int,\"valore\": float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0501abf",
   "metadata": {},
   "source": [
    "<a id='meteo_data_csv'></a>\n",
    "# Import meteorological data from ARPA .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b9674",
   "metadata": {},
   "source": [
    "Go back to [meteorological data import from API](#meteo_data_api) data if required. Used to access data from past years (not current one)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a666a4b5",
   "metadata": {},
   "source": [
    "Download the .csv data for the selected year in a zip folder. Read the .csv file and put it in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c268e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = my_methods.meteo_sensor(year)\n",
    "r2 = requests.get(csv_url, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0a4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_zip = open('meteo_'+str(year)+'.zip', 'wb').write(r2.content)\n",
    "archive = zipfile.ZipFile('meteo_'+str(year)+'.zip', 'r')\n",
    "data = archive.open(str(year)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data = pd.read_csv(data, dtype={\"IdSensore\": int,\"Valore\": float, \"Stato\": str, \"idOperatore\":str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34163fea",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data.rename(columns={'IdSensore': 'idsensore','Data': 'data','idOperatore': 'idoperatore','Stato': 'stato','Valore': 'valore'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9ebe5",
   "metadata": {},
   "source": [
    "Set date format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456d37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data['data'] =  pd.to_datetime(meteo_data['data'], format='%d/%m/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb929267",
   "metadata": {},
   "source": [
    "Filter date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (meteo_data.data >= start_date) & (meteo_data.data < end_date)\n",
    "meteo_data = meteo_data.loc[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896ee3a",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b0b80f",
   "metadata": {},
   "source": [
    "# Meteorological data processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f6280",
   "metadata": {},
   "source": [
    "Drop \"stato\", \"idoperatore\" columns and select valid data different from -9999:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_data = meteo_data.drop(columns=['stato', 'idoperatore'])\n",
    "meteo_data = meteo_data[meteo_data.valore.astype(float) != -9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7666d5",
   "metadata": {},
   "source": [
    "Get sensors unique types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_st_descr.tipologia.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba773355",
   "metadata": {},
   "source": [
    "Select sensors adding to the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c37e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sensor_sel = ['Precipitazione','Temperatura','Umidità Relativa','Direzione Vento','Velocità Vento', 'Radiazione Globale']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95403cea",
   "metadata": {},
   "source": [
    "Join sensors description and information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_table = pd.merge(meteo_data, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b27716",
   "metadata": {},
   "source": [
    "Select sensor by type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91118ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_table['tipologia'].astype(str)\n",
    "meteo_table = meteo_table[meteo_table['tipologia'].isin(m_sensor_sel)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d26c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st = meteo_table.loc[meteo_table['tipologia'] == 'Temperatura']\n",
    "prec_st = meteo_table.loc[meteo_table['tipologia'] == 'Precipitazione']\n",
    "air_hum_st = meteo_table.loc[meteo_table['tipologia'] == 'Umidità Relativa']\n",
    "wind_dir_st = meteo_table.loc[meteo_table['tipologia'] == 'Direzione Vento']\n",
    "wind_speed_st = meteo_table.loc[meteo_table['tipologia'] == 'Velocità Vento']\n",
    "rad_glob_st = meteo_table.loc[meteo_table['tipologia'] == 'Radiazione Globale']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a88f6ec",
   "metadata": {},
   "source": [
    "Calculate Z-Score to remove outliers and calculate mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbacd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st['zscore'] = np.abs(stats.zscore(temp_st['valore'], nan_policy='propagate'))\n",
    "temp_st = temp_st[temp_st.zscore < threshold]\n",
    "temp_st = temp_st.groupby(['idsensore'],as_index=False).mean()\n",
    "temp_st = pd.merge(temp_st, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a8ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precipitation values less than 100 to remove outliers\n",
    "prec_st = prec_st[prec_st.valore < 100]\n",
    "prec_st = prec_st.groupby(['idsensore'],as_index=False).mean()\n",
    "prec_st = pd.merge(prec_st, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ab7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_hum_st['zscore'] = np.abs(stats.zscore(air_hum_st['valore'], nan_policy='propagate'))\n",
    "air_hum_st = air_hum_st[air_hum_st.zscore < threshold]\n",
    "air_hum_st = air_hum_st.groupby(['idsensore'],as_index=False).mean()\n",
    "air_hum_st = pd.merge(air_hum_st, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18062c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_st['zscore'] = np.abs(stats.zscore(wind_dir_st['valore'], nan_policy='propagate'))\n",
    "wind_dir_st = wind_dir_st[wind_dir_st.zscore < threshold]\n",
    "wind_dir_st = wind_dir_st.groupby(['idsensore'],as_index=False).mean()\n",
    "wind_dir_st = pd.merge(wind_dir_st, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_st['zscore'] = np.abs(stats.zscore(wind_speed_st['valore'], nan_policy='propagate'))\n",
    "wind_speed_st = wind_speed_st[wind_speed_st.zscore < threshold]\n",
    "wind_speed_st = wind_speed_st.groupby(['idsensore'],as_index=False).mean()\n",
    "wind_speed_st = pd.merge(wind_speed_st, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6033ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_glob_st['zscore'] = np.abs(stats.zscore(rad_glob_st['valore'], nan_policy='propagate'))\n",
    "rad_glob_st = rad_glob_st[rad_glob_st.zscore < threshold]\n",
    "rad_glob_st = rad_glob_st.groupby(['idsensore'],as_index=False).mean()\n",
    "rad_glob_st = pd.merge(rad_glob_st, meteo_st_descr, on = 'idsensore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb40326d",
   "metadata": {},
   "source": [
    "Save sensors separately and create a .gpkg file for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879efd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gdf = gpd.GeoDataFrame(temp_st, geometry=gpd.points_from_xy(temp_st.lng, temp_st.lat))\n",
    "temp_gdf = temp_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b216321",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_gdf = gpd.GeoDataFrame(prec_st, geometry=gpd.points_from_xy(prec_st.lng, prec_st.lat))\n",
    "prec_gdf = prec_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d24e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "air_hum_gdf = gpd.GeoDataFrame(air_hum_st, geometry=gpd.points_from_xy(air_hum_st.lng, air_hum_st.lat))\n",
    "air_hum_gdf = air_hum_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b468a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dir_gdf = gpd.GeoDataFrame(wind_dir_st, geometry=gpd.points_from_xy(wind_dir_st.lng, wind_dir_st.lat))\n",
    "wind_dir_gdf = wind_dir_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773515be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_gdf = gpd.GeoDataFrame(wind_speed_st, geometry=gpd.points_from_xy(wind_speed_st.lng, wind_speed_st.lat))\n",
    "wind_speed_gdf = wind_speed_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_glob_gdf = gpd.GeoDataFrame(rad_glob_st, geometry=gpd.points_from_xy(rad_glob_st.lng, rad_glob_st.lat))\n",
    "rad_glob_gdf = rad_glob_gdf.set_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7280ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gdf.to_file(cwd+\"/temp/temp_st.gpkg\", driver=\"GPKG\")\n",
    "prec_gdf.to_file(cwd+\"/temp/prec_st.gpkg\", driver=\"GPKG\")\n",
    "air_hum_gdf.to_file(cwd+\"/temp/air_hum_st.gpkg\", driver=\"GPKG\")\n",
    "wind_dir_gdf.to_file(cwd+\"/temp/wind_dir_st.gpkg\", driver=\"GPKG\")\n",
    "wind_speed_gdf.to_file(cwd+\"/temp/wind_speed_st.gpkg\", driver=\"GPKG\")\n",
    "rad_glob_gdf.to_file(cwd+\"/temp/rad_glob_st.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb6f3c",
   "metadata": {},
   "source": [
    "# Sensor interpolation using Radial Basis Functions (RBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b7616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo import ogr\n",
    "import rasterio as rio\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.crs import CRS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import Rbf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_gdf = pm25_gdf.to_crs('epsg:32632')\n",
    "co_gdf = co_gdf.to_crs('epsg:32632')\n",
    "no2_gdf = no2_gdf.to_crs('epsg:32632')\n",
    "so2_gdf = so2_gdf.to_crs('epsg:32632')\n",
    "nh3_gdf = nh3_gdf.to_crs('epsg:32632')\n",
    "nox_gdf = nox_gdf.to_crs('epsg:32632')\n",
    "pm10_gdf = pm10_gdf.to_crs('epsg:32632')\n",
    "o3_gdf = o3_gdf.to_crs('epsg:32632')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf1ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_gdf = temp_gdf.to_crs('epsg:32632')\n",
    "prec_gdf = prec_gdf.to_crs('epsg:32632')\n",
    "air_hum_gdf = air_hum_gdf.to_crs('epsg:32632')\n",
    "wind_dir_gdf = wind_dir_gdf.to_crs('epsg:32632')\n",
    "wind_speed_gdf = wind_speed_gdf.to_crs('epsg:32632')\n",
    "rad_glob_gdf = rad_glob_gdf.to_crs('epsg:32632')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab7b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = gdal.Open(cwd+\"/bounding_box/bounding_box_buffer20_raster_32632.tif\")\n",
    "gt = bb.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62971f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ulx = gt[0]\n",
    "uly = gt[3]\n",
    "resx = gt[1]\n",
    "resy = gt[5]\n",
    "xsize = bb.RasterXSize\n",
    "ysize = bb.RasterYSize\n",
    "lrx = ulx + xsize * resx\n",
    "lry = uly + ysize * resy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsize, ysize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f68fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ulx, uly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrx, lry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rRes = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now interpolate all the ARPA/ESA stations. \n",
    "# Must implement a check if number of station over the Lombardy region is too low -> don't interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed678fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xRange = np.arange(ulx,lrx+rRes,rRes)\n",
    "yRange = np.arange(lry,uly+rRes,rRes)\n",
    "gridX,gridY = np.meshgrid(xRange, yRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56130a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_dict = {'pm25_gdf':pm25_gdf, 'co_gdf':co_gdf, 'no2_gdf':no2_gdf, 'so2_gdf':so2_gdf,\n",
    "           'nh3_gdf':nh3_gdf, 'nox_gdf':nox_gdf, 'pm10_gdf':pm10_gdf, 'o3_gdf':o3_gdf}\n",
    "\n",
    "meteo_dict = {'temp_gdf':temp_gdf, 'prec_gdf':prec_gdf, 'air_hum_gdf':air_hum_gdf, 'wind_dir_gdf':wind_dir_gdf,\n",
    "           'wind_speed_gdf':wind_speed_gdf, 'rad_glob_gdf':rad_glob_gdf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da672f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in aq_dict:\n",
    "    east = aq_dict[key].geometry.x\n",
    "    north = aq_dict[key].geometry.y\n",
    "    value = aq_dict[key][['valore']]\n",
    "    \n",
    "    rbf = Rbf(east, north, value, function='linear')\n",
    "    z_new = rbf(gridX.ravel(), gridY.ravel()).reshape(gridX.shape)\n",
    "    print(key)\n",
    "    plt.pcolor(gridX, gridY, z_new);\n",
    "    plt.plot(east, north, 'o', markerfacecolor='blue');\n",
    "    plt.xlabel('East'); plt.ylabel('North');\n",
    "    plt.title('RBF Linear interpolation');\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes,rRes)\n",
    "\n",
    "    new_dataset = rio.open(cwd +'/temp/aq_rbf_'+key[:(len(key)-4)]+'.tif', 'w', driver='GTiff',\n",
    "                            height = z_new.shape[0], width = z_new.shape[1],\n",
    "                            count=1, dtype=str(z_new.dtype),\n",
    "                            crs='+proj=utm +zone=32 +datum=WGS84 +units=m +no_defs',\n",
    "                            transform=transform)\n",
    "\n",
    "    new_dataset.write(z_new, 1)\n",
    "    new_dataset.close()\n",
    "    #Warp with GDAL since rasterio and rasterstats affine transformation don't work in the grid processing notebook\n",
    "    ds = gdal.Warp(cwd +'/temp/int_'+key[:(len(key)-4)]+'.tif', cwd +'/temp/aq_rbf_'+key[:(len(key)-4)]+'.tif', dstSRS='EPSG:32632',\n",
    "                outputType=gdal.GDT_Float64, xRes=rRes, yRes=rRes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72b5db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in meteo_dict:\n",
    "    east = meteo_dict[key].geometry.x\n",
    "    north = meteo_dict[key].geometry.y\n",
    "    value = meteo_dict[key][['valore']]\n",
    "    \n",
    "    rbf = Rbf(east, north, value, function='linear')\n",
    "    z_new = rbf(gridX.ravel(), gridY.ravel()).reshape(gridX.shape)\n",
    "    print(key)\n",
    "    plt.pcolor(gridX, gridY, z_new);\n",
    "    plt.plot(east, north, 'o');\n",
    "    plt.xlabel('East'); plt.ylabel('North');\n",
    "    plt.title('RBF Linear interpolation');\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes,rRes)\n",
    "\n",
    "    new_dataset = rio.open(cwd +'/temp/meteo_rbf_'+key[:(len(key)-4)]+'.tif', 'w', driver='GTiff',\n",
    "                            height = z_new.shape[0], width = z_new.shape[1],\n",
    "                            count=1, dtype=str(z_new.dtype),\n",
    "                            crs='+proj=utm +zone=32 +datum=WGS84 +units=m +no_defs',\n",
    "                            transform=transform)\n",
    "\n",
    "    new_dataset.write(z_new, 1)\n",
    "    new_dataset.close()\n",
    "    #Warp with GDAL since rasterio and rasterstats affine transformation don't work in the grid processing notebook\n",
    "    ds = gdal.Warp(cwd +'/temp/int_'+key[:(len(key)-4)]+'.tif', cwd +'/temp/meteo_rbf_'+key[:(len(key)-4)]+'.tif', dstSRS='EPSG:32632',\n",
    "                outputType=gdal.GDT_Float64, xRes=rRes, yRes=rRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e850fbc2",
   "metadata": {},
   "source": [
    "Statistics, Points Sampling with stations positions and rasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead14be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in aq_dict:\n",
    "    raster = rio.open(cwd +'/temp/int_'+key[:(len(key)-4)]+'.tif')\n",
    "    east = aq_dict[key].geometry.x\n",
    "    north = aq_dict[key].geometry.y\n",
    "    value = aq_dict[key][['valore']]\n",
    "    aq_dict[key].index = range(len(aq_dict[key]))\n",
    "    coords = [(x,y) for x, y in zip(aq_dict[key].geometry.x,aq_dict[key].geometry.y)]\n",
    "    aq_dict[key]['Raster Value'] = [x[0] for x in raster.sample(coords)]\n",
    "    rmse = ((aq_dict[key]['Raster Value'] - aq_dict[key]['valore'])**2)**(1/2)\n",
    "    print(\"Data name : {name}\".format(name = key))\n",
    "    print(\"Max value from stations: {value}\".format(value = aq_dict[key]['valore'].max()))\n",
    "    print(\"Max value from interpolated raster: {value}\".format(value=aq_dict[key]['Raster Value'].max()))\n",
    "    print(\"Min value from stations: {value}\".format(value = aq_dict[key]['valore'].min()))\n",
    "    print(\"Min value from interpolated raster: {value}\".format(value=aq_dict[key]['Raster Value'].min()))\n",
    "    print(\"RMSE max: {rmse}\".format(rmse = rmse.max()))\n",
    "    print(\"RMSE mean : {rmse}\".format(rmse = rmse.mean()))\n",
    "    plt.hist(aq_dict[key]['Raster Value'], label = 'Raster Values', histtype='step')\n",
    "    plt.hist(aq_dict[key]['valore'], label = 'Stations Values', histtype='step')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    print(\"----------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236f96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in meteo_dict:\n",
    "    raster = rio.open(cwd +'/temp/int_'+key[:(len(key)-4)]+'.tif')\n",
    "    east = meteo_dict[key].geometry.x\n",
    "    north = meteo_dict[key].geometry.y\n",
    "    value = meteo_dict[key][['valore']]\n",
    "    meteo_dict[key].index = range(len(meteo_dict[key]))\n",
    "    coords = [(x,y) for x, y in zip(meteo_dict[key].geometry.x, meteo_dict[key].geometry.y)]\n",
    "    meteo_dict[key]['Raster Value'] = [x[0] for x in raster.sample(coords)]\n",
    "    rmse = ((meteo_dict[key]['Raster Value'] - meteo_dict[key]['valore'])**2)**(1/2)\n",
    "    print(\"Data name : {name}\".format(name = key))\n",
    "    print(\"Max value from stations: {value}\".format(value = meteo_dict[key]['valore'].max()))\n",
    "    print(\"Max value from interpolated raster: {value}\".format(value=meteo_dict[key]['Raster Value'].max()))\n",
    "    print(\"Min value from stations: {value}\".format(value = meteo_dict[key]['valore'].min()))\n",
    "    print(\"Min value from interpolated raster: {value}\".format(value=meteo_dict[key]['Raster Value'].min()))\n",
    "    print(\"RMSE max: {rmse}\".format(rmse = rmse.max()))\n",
    "    print(\"RMSE mean : {rmse}\".format(rmse = rmse.mean()))\n",
    "    plt.hist(meteo_dict[key]['Raster Value'], label = 'Raster Values', histtype='step')\n",
    "    plt.hist(meteo_dict[key]['valore'], label = 'Stations Values', histtype='step')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    print(\"----------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9358e1",
   "metadata": {},
   "source": [
    "Kriging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pykrige.ok import OrdinaryKriging\n",
    "# from pykrige.kriging_tools import write_asc_grid\n",
    "# import pykrige.kriging_tools as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab607b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in aq_dict:\n",
    "#     east = aq_dict[key].geometry.x\n",
    "#     north = aq_dict[key].geometry.y\n",
    "#     value = aq_dict[key][['valore']]\n",
    "#     n_sensor = aq_dict[key].shape[0]  #VERIFICARE nlags in funzione del numero di sensori (defaul 6)\n",
    "#     lag = int(math.sqrt(n_sensor))\n",
    "    \n",
    "#     OK = OrdinaryKriging(east, north,value, weight=True,nlags= lag ,variogram_model='power',coordinates_type='euclidean') #verbose=True, enable_plotting=False, weight=w\n",
    "#     # print(UniversalKriging.__doc__ )\n",
    "#     gridded, ss1 = OK.execute('grid', xRange, yRange)\n",
    "#     transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes,rRes)\n",
    "#     rasterCrs = CRS.from_epsg(32632)\n",
    "#     #definition, register and close of interpolated raster\n",
    "#     interpRaster = rio.open(cwd +'/temp/aq_krig_'+key[:(len(key)-4)]+'.tif',\n",
    "#                                     'w',\n",
    "#                                     driver='GTiff',\n",
    "#                                     height=gridded.shape[0],\n",
    "#                                     width=gridded.shape[1],\n",
    "#                                     count=1,\n",
    "#                                     nodata = -9999,\n",
    "#                                     dtype=gridded.dtype,\n",
    "#                                     crs=rasterCrs,\n",
    "#                                     transform=transform,\n",
    "#                                     )\n",
    "#     interpRaster.write(gridded, 1)\n",
    "#     interpRaster.close()\n",
    "#     #Warp with GDAL since rasterio and rasterstats affine transformation don't work in the grid processing notebook\n",
    "#     ds = gdal.Warp(cwd +'/temp/int_'+key[:(len(key)-4)]+'.tif', cwd +'/temp/aq_krig_'+key[:(len(key)-4)]+'.tif', dstSRS='EPSG:32632',\n",
    "#                outputType=gdal.GDT_Float64, xRes=rRes, yRes=rRes)\n",
    "#     print(key)\n",
    "#     plt.imshow(gridded)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in meteo_dict:\n",
    "#     east = meteo_dict[key].geometry.x\n",
    "#     north = meteo_dict[key].geometry.y\n",
    "#     value = meteo_dict[key][['valore']]\n",
    "#     n_sensor = meteo_dict[key].shape[0]  #VERIFICARE nlags in funzione del numero di sensori (defaul 6)\n",
    "#     lag = int(math.sqrt(n_sensor))\n",
    "    \n",
    "#     OK = OrdinaryKriging(east, north, value, nlags= lag,\n",
    "#                  weight=True, variogram_model='power',coordinates_type='euclidean') #verbose=True, enable_plotting=False, weight=w\n",
    "#     # print(OrdinaryKriging.__doc__)\n",
    "#     gridded, ss1 = OK.execute('grid', xRange, yRange)\n",
    "#     transform = Affine.translation(gridX[0][0]-rRes/2, gridY[0][0]-rRes/2)*Affine.scale(rRes,rRes)\n",
    "#     rasterCrs = CRS.from_epsg(32632)\n",
    "#     #definition, register and close of interpolated raster\n",
    "#     interpRaster = rio.open(cwd +'/temp/meteo_krig_'+key[:(len(key)-4)]+'.tif',\n",
    "#                                     'w',\n",
    "#                                     driver='GTiff',\n",
    "#                                     height= gridded.shape[0],\n",
    "#                                     width= gridded.shape[1],\n",
    "#                                     count=1,\n",
    "#                                     nodata = -9999,\n",
    "#                                     dtype=gridded.dtype,\n",
    "#                                     crs=rasterCrs,\n",
    "#                                     transform=transform,\n",
    "#                                     )\n",
    "#     interpRaster.write(gridded, 1)\n",
    "#     interpRaster.close()\n",
    "#     #Warp with GDAL since rasterio and rasterstats affine transformation don't work in the grid processing notebook\n",
    "#     ds = gdal.Warp(cwd +'/temp/int_'+key[:(len(key)-4)]+'.tif', cwd +'/temp/meteo_krig_'+key[:(len(key)-4)]+'.tif', dstSRS='EPSG:32632',\n",
    "#                outputType=gdal.GDT_Float64, xRes=rRes, yRes=rRes)\n",
    "#     print(key)\n",
    "#     print(lag)\n",
    "#     plt.imshow(gridded)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd721f2d",
   "metadata": {},
   "source": [
    "Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4277434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPOLATION USING GDAL\n",
    "# pts = ogr.Open(cwd+'/temp/air_hum_st.gpkg', update = True)\n",
    "# layer=pts.GetLayer()\n",
    "\n",
    "# to generate a an interpolation using GDAL library\n",
    "# pts = layer = None\n",
    "# idw = gdal.Grid(\"idw.tif\", (cwd+'/temp/air_hum_st.gpkg'), zfield=\"valore\",\n",
    "#                algorithm = \"invdist\", outputBounds = [ulx,uly,lrx,lry],\n",
    "#                width = xsize, height = ysize)\n",
    "# idw = None\n",
    "\n",
    "# points = list(zip(air_hum_st.lng,air_hum_st.lat))\n",
    "\n",
    "# gridded = griddata(points, value, (gridX,gridY), method='linear',fill_value=0)\n",
    "\n",
    "# gridded = gridded.reshape((gridded.shape[0], gridded.shape[1]))\n",
    "\n",
    "# plt.imshow(gridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc802025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mask data using date range\n",
    "#mask = (meteo_data['data'] >= start_date) & (meteo_data['data'] < end_date)\n",
    "#meteo_data = meteo_data.loc[mask]\n",
    "#meteo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc21b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(arpa_df.columns))\n",
    "# print(arpa_df['idsensore'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c82fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = client.get_all(dati, idsensore = \"100\", data='2022-01-20')\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e05945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arpa_df.loc[arpa_df['idsensore'] == \"10377\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec9c574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
